#!/usr/bin/env python3
"""
æ’­å®¢è…³æœ¬ç¿»è­¯å™¨
å°‡ä¸­æ–‡æ’­å®¢è…³æœ¬ç¿»è­¯æˆå®¢èª
"""

import asyncio
import sys
import json
import re
import argparse
from pathlib import Path
from datetime import datetime

# Add project root to Python path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from app.services.translation_service import TranslationService
from app.services.tts_service import TTSService

async def translate_podcast_script():
    """ç¿»è­¯æ’­å®¢è…³æœ¬"""
    
    print("ğŸ™ï¸ Hakkast æ’­å®¢è…³æœ¬ç¿»è­¯å™¨")
    print("=" * 60)
    
    # è®€å–åŸå§‹è…³æœ¬
    script_file = Path(__file__).parent / "podcast_script_technology_news_3articles.txt"
    
    if not script_file.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è…³æœ¬æ–‡ä»¶: {script_file}")
        return
    
    with open(script_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    print(f"ğŸ“„ è®€å–è…³æœ¬æ–‡ä»¶: {script_file.name}")
    
    # åˆå§‹åŒ–ç¿»è­¯æœå‹™
    translation_service = TranslationService()
    
    # è§£æè…³æœ¬å…§å®¹
    lines = content.split('\n')
    translated_lines = []
    dialogue_segments = []
    
    print("\nğŸ”„ é–‹å§‹ç¿»è­¯...")
    
    dialogue_pattern = r'^(ä¸»æŒäºº[AB]):\s*(.+)$'
    segment_count = 0
    
    for i, line in enumerate(lines):
        print(f"è™•ç†ç¬¬ {i+1}/{len(lines)} è¡Œ", end='\r')
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºå°è©±è¡Œ
        match = re.match(dialogue_pattern, line.strip())
        
        if match:
            speaker = match.group(1)
            text = match.group(2)
            
            # ç¿»è­¯å°è©±å…§å®¹
            try:
                result = await translation_service.translate_chinese_to_hakka(text)
                
                hakka_text = result['hakka_text']
                romanization = result['romanization']
                
                # å‰µå»ºç¿»è­¯å¾Œçš„è¡Œ
                translated_line = f"{speaker}: {hakka_text}"
                translated_lines.append(translated_line)
                
                # ä¿å­˜å°è©±æ®µè½è³‡è¨Š
                segment_count += 1
                dialogue_segments.append({
                    "segment_id": segment_count,
                    "speaker": speaker,
                    "original_text": text,
                    "hakka_text": hakka_text,
                    "romanization": romanization,
                    "estimated_duration": result['estimated_speech_duration'],
                    "line_number": i + 1
                })
                
            except Exception as e:
                print(f"\nâŒ ç¿»è­¯å¤±æ•— (ç¬¬ {i+1} è¡Œ): {e}")
                translated_lines.append(line)  # ä¿ç•™åŸæ–‡
        else:
            # éå°è©±è¡Œç›´æ¥ä¿ç•™
            translated_lines.append(line)
    
    print(f"\nâœ… ç¿»è­¯å®Œæˆï¼å…±è™•ç† {segment_count} æ®µå°è©±")
    
    # ç”Ÿæˆç¿»è­¯å¾Œçš„è…³æœ¬æ–‡ä»¶
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # 1. å®Œæ•´å®¢èªè…³æœ¬
    hakka_script_file = Path(__file__).parent / f"podcast_script_hakka_{timestamp}.txt"
    with open(hakka_script_file, 'w', encoding='utf-8') as f:
        f.write("Hakkast å®¢èªæ’­å®¢è…³æœ¬\n")
        f.write("=" * 60 + "\n\n")
        f.write("ç¿»è­¯æ™‚é–“: " + datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S") + "\n")
        f.write("åŸå§‹è…³æœ¬: podcast_script_technology_news_3articles.txt\n\n")
        f.write("=" * 60 + "\n")
        f.write("å®Œæ•´å®¢èªå°è©±å…§å®¹:\n\n")
        f.write('\n'.join(translated_lines))
    
    print(f"ğŸ’¾ å®¢èªè…³æœ¬å·²ä¿å­˜: {hakka_script_file.name}")
    
    # 2. è©³ç´°å°è©±è³‡è¨Š (JSONæ ¼å¼)
    dialogue_json_file = Path(__file__).parent / f"podcast_dialogue_hakka_{timestamp}.json"
    with open(dialogue_json_file, 'w', encoding='utf-8') as f:
        json.dump({
            "metadata": {
                "translation_time": datetime.now().isoformat(),
                "original_script": "podcast_script_technology_news_3articles.txt",
                "total_segments": len(dialogue_segments),
                "total_estimated_duration": sum(seg['estimated_duration'] for seg in dialogue_segments)
            },
            "dialogue_segments": dialogue_segments
        }, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ å°è©±è³‡è¨Šå·²ä¿å­˜: {dialogue_json_file.name}")
    
    # 3. æ‹¼éŸ³å°ç…§è¡¨
    romanization_file = Path(__file__).parent / f"podcast_romanization_{timestamp}.txt"
    with open(romanization_file, 'w', encoding='utf-8') as f:
        f.write("Hakkast æ’­å®¢å®¢èªæ‹¼éŸ³å°ç…§è¡¨\n")
        f.write("=" * 60 + "\n\n")
        f.write("æ‹¼éŸ³ç³»çµ±: å››ç¸£è…”æ•¸å­—æ¨™èª¿æ³•\n")
        f.write("ç¿»è­¯æ™‚é–“: " + datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S") + "\n\n")
        f.write("=" * 60 + "\n\n")
        
        for segment in dialogue_segments:
            f.write(f"ã€{segment['speaker']}ã€‘\n")
            f.write(f"åŸæ–‡: {segment['original_text']}\n")
            f.write(f"å®¢èª: {segment['hakka_text']}\n")
            f.write(f"æ‹¼éŸ³: {segment['romanization']}\n")
            f.write(f"é ä¼°èªéŸ³æ™‚é•·: {segment['estimated_duration']:.1f}ç§’\n")
            f.write("-" * 40 + "\n\n")
    
    print(f"ğŸ’¾ æ‹¼éŸ³å°ç…§è¡¨å·²ä¿å­˜: {romanization_file.name}")
    
    # çµ±è¨ˆè³‡è¨Š
    total_duration = sum(seg['estimated_duration'] for seg in dialogue_segments)
    print(f"\nğŸ“Š ç¿»è­¯çµ±è¨ˆ:")
    print(f"   å°è©±æ®µè½: {len(dialogue_segments)} æ®µ")
    print(f"   é ä¼°ç¸½æ™‚é•·: {total_duration:.1f}ç§’ ({total_duration/60:.1f}åˆ†é˜)")
    print(f"   å¹³å‡æ¯æ®µæ™‚é•·: {total_duration/len(dialogue_segments):.1f}ç§’")
    
    # é¡¯ç¤ºå‰å¹¾æ®µç¿»è­¯ç¤ºä¾‹
    print(f"\nğŸ­ ç¿»è­¯ç¤ºä¾‹ (å‰5æ®µ):")
    for i, segment in enumerate(dialogue_segments[:5], 1):
        print(f"\n{i}. ã€{segment['speaker']}ã€‘")
        print(f"   åŸæ–‡: {segment['original_text'][:80]}{'...' if len(segment['original_text']) > 80 else ''}")
        print(f"   å®¢èª: {segment['hakka_text'][:80]}{'...' if len(segment['hakka_text']) > 80 else ''}")
    
    await translation_service.close()
    
    return {
        "hakka_script_file": hakka_script_file,
        "dialogue_json_file": dialogue_json_file,
        "romanization_file": romanization_file,
        "total_segments": len(dialogue_segments),
        "total_duration": total_duration
    }

async def create_tts_ready_segments():
    """å‰µå»ºé©åˆTTSçš„åˆ†æ®µæ–‡ä»¶"""
    
    print("\nğŸ¤ å‰µå»ºTTSå°±ç·’åˆ†æ®µ...")
    
    # æŸ¥æ‰¾æœ€æ–°çš„å°è©±JSONæ–‡ä»¶
    json_files = list(Path(__file__).parent.glob("podcast_dialogue_hakka_*.json"))
    if not json_files:
        print("âŒ æ‰¾ä¸åˆ°å°è©±JSONæ–‡ä»¶")
        return
    
    latest_json = sorted(json_files)[-1]
    
    with open(latest_json, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    dialogue_segments = data['dialogue_segments']
    
    # å‰µå»ºTTSåˆ†æ®µæ–‡ä»¶
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    tts_file = Path(__file__).parent / f"tts_segments_{timestamp}.json"
    
    tts_segments = []
    for segment in dialogue_segments:
        tts_segments.append({
            "id": f"seg_{segment['segment_id']:03d}",
            "speaker": segment['speaker'],
            "text": segment['hakka_text'],
            "romanization": segment['romanization'],
            "duration": segment['estimated_duration'],
            "voice_settings": {
                "language": "hakka",
                "dialect": "sixian",
                "speed": "normal",
                "pitch": "natural"
            }
        })
    
    tts_data = {
        "podcast_info": {
            "title": "Hakkast ç§‘æŠ€æ–°èæ’­å®¢",
            "episode": "3ç¯‡ç§‘æŠ€æ–°èè¨è«–",
            "total_segments": len(tts_segments),
            "estimated_total_duration": sum(seg['duration'] for seg in tts_segments),
            "created_at": datetime.now().isoformat()
        },
        "tts_segments": tts_segments
    }
    
    with open(tts_file, 'w', encoding='utf-8') as f:
        json.dump(tts_data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ TTSåˆ†æ®µæ–‡ä»¶å·²ä¿å­˜: {tts_file.name}")
    print(f"   ç¸½åˆ†æ®µæ•¸: {len(tts_segments)}")
    print(f"   é ä¼°ç¸½æ™‚é•·: {tts_data['podcast_info']['estimated_total_duration']:.1f}ç§’")
    
    return tts_file

async def test_tts_generation():
    """æ¸¬è©¦TTSç”ŸæˆåŠŸèƒ½"""
    
    print("\nğŸ¤ é–‹å§‹TTSèªéŸ³ç”Ÿæˆæ¸¬è©¦...")
    
    # æŸ¥æ‰¾æœ€æ–°çš„å°è©±JSONæ–‡ä»¶
    json_files = list(Path(__file__).parent.glob("podcast_dialogue_hakka_*.json"))
    if not json_files:
        print("âŒ æ‰¾ä¸åˆ°å°è©±JSONæ–‡ä»¶ï¼Œè«‹å…ˆé‹è¡Œç¿»è­¯åŠŸèƒ½")
        return
    
    latest_json = sorted(json_files)[-1]
    print(f"ğŸ“ ä½¿ç”¨å°è©±æ–‡ä»¶: {latest_json.name}")
    
    with open(latest_json, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    dialogue_segments = data['dialogue_segments']
    
    # åˆå§‹åŒ–TTSæœå‹™
    tts_service = TTSService()
    
    try:
        # ç™»å…¥TTSæœå‹™
        print("ğŸ” æ­£åœ¨ç™»å…¥TTSæœå‹™...")
        login_success = await tts_service.login()
        
        if not login_success:
            print("âš ï¸  TTSæœå‹™ç™»å…¥å¤±æ•—ï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
        else:
            print("âœ… TTSæœå‹™ç™»å…¥æˆåŠŸ")
        
        # æ¸¬è©¦å‰3æ®µå°è©±
        test_segments = dialogue_segments[:3]  # åªæ¸¬è©¦å‰3æ®µ
        generated_audio = []
        
        print(f"\nğŸµ é–‹å§‹ç”ŸæˆèªéŸ³ (æ¸¬è©¦ {len(test_segments)} æ®µ)...")
        
        for i, segment in enumerate(test_segments, 1):
            print(f"\nè™•ç†ç¬¬ {i} æ®µ: ã€{segment['speaker']}ã€‘")
            print(f"å®¢èªæ–‡æœ¬: {segment['hakka_text'][:60]}...")
            
            try:
                # ç”ŸæˆèªéŸ³
                audio_result = await tts_service.generate_hakka_audio(
                    hakka_text=segment['hakka_text'],
                    romanization=segment['romanization']
                )
                
                if audio_result.get('audio_path'):
                    print(f"âœ… èªéŸ³ç”ŸæˆæˆåŠŸ: {audio_result['audio_url']}")
                    print(f"   é ä¼°æ™‚é•·: {audio_result['duration']}ç§’")
                    print(f"   ä½¿ç”¨æ¨¡å‹: {audio_result['voice_model']}")
                    
                    generated_audio.append({
                        **segment,
                        "audio_info": audio_result
                    })
                else:
                    print(f"âŒ èªéŸ³ç”Ÿæˆå¤±æ•—: {audio_result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
                    
            except Exception as e:
                print(f"âŒ è™•ç†ç¬¬ {i} æ®µæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        # ä¿å­˜æ¸¬è©¦çµæœ
        if generated_audio:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            test_result_file = Path(__file__).parent / f"tts_test_result_{timestamp}.json"
            
            test_data = {
                "test_info": {
                    "test_time": datetime.now().isoformat(),
                    "source_file": latest_json.name,
                    "total_tested": len(test_segments),
                    "successful_generated": len(generated_audio),
                    "login_success": login_success
                },
                "generated_audio": generated_audio
            }
            
            with open(test_result_file, 'w', encoding='utf-8') as f:
                json.dump(test_data, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ’¾ æ¸¬è©¦çµæœå·²ä¿å­˜: {test_result_file.name}")
            
            # é¡¯ç¤ºç”Ÿæˆçš„éŸ³é »æ–‡ä»¶åˆ—è¡¨
            print(f"\nğŸµ ç”Ÿæˆçš„éŸ³é »æ–‡ä»¶:")
            for i, audio in enumerate(generated_audio, 1):
                audio_info = audio['audio_info']
                print(f"   {i}. ã€{audio['speaker']}ã€‘ - {audio_info['audio_url']}")
                print(f"      æ–‡æœ¬: {audio['hakka_text'][:40]}...")
                print(f"      æ™‚é•·: {audio_info['duration']}ç§’")
        
        print(f"\nğŸ“Š TTSæ¸¬è©¦çµ±è¨ˆ:")
        print(f"   æ¸¬è©¦æ®µè½: {len(test_segments)} æ®µ")
        print(f"   æˆåŠŸç”Ÿæˆ: {len(generated_audio)} æ®µ")
        print(f"   æˆåŠŸç‡: {len(generated_audio)/len(test_segments)*100:.1f}%")
        
    finally:
        # ç™»å‡ºä¸¦é—œé–‰æœå‹™
        await tts_service.logout()
        await tts_service.close()
        print("ğŸ”“ TTSæœå‹™å·²ç™»å‡º")
    
    return generated_audio

async def test_tts_only():
    """åƒ…æ¸¬è©¦TTSåŠŸèƒ½ï¼ˆä¸é€²è¡Œç¿»è­¯ï¼‰"""
    
    print("ğŸ¤ TTSç¨ç«‹æ¸¬è©¦æ¨¡å¼")
    print("=" * 50)
    
    try:
        generated_audio = await test_tts_generation()
        
        if generated_audio:
            print(f"\nğŸ‰ TTSæ¸¬è©¦å®Œæˆ! ç”Ÿæˆäº† {len(generated_audio)} å€‹éŸ³é »æ–‡ä»¶")
            
            # æ’­æ”¾å»ºè­°
            print(f"\nğŸ’¡ æ’­æ”¾å»ºè­°:")
            print(f"   1. éŸ³é »æ–‡ä»¶ä½æ–¼: backend/static/audio/")
            print(f"   2. å¯ä½¿ç”¨ç€è¦½å™¨è¨ªå•: http://localhost:8000/static/audio/[æ–‡ä»¶å]")
            print(f"   3. æˆ–ç›´æ¥ç”¨éŸ³é »æ’­æ”¾å™¨æ‰“é–‹æ–‡ä»¶")
        else:
            print(f"\nâŒ TTSæ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥:")
            print(f"   1. TTSæœå‹™é…ç½®æ˜¯å¦æ­£ç¢º")
            print(f"   2. æ˜¯å¦å­˜åœ¨ç¿»è­¯å¾Œçš„å°è©±æ–‡ä»¶")
            print(f"   3. ç¶²çµ¡é€£æ¥æ˜¯å¦æ­£å¸¸")
            
    except Exception as e:
        print(f"âŒ TTSæ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

async def main():
    """ä¸»è¦åŸ·è¡Œå‡½æ•¸"""
    
    print("ğŸ™ï¸ Hakkast æ’­å®¢è…³æœ¬ç¿»è­¯èˆ‡TTSæ¸¬è©¦ç³»çµ±")
    print("=" * 70)
    
    try:
        # ç¿»è­¯æ’­å®¢è…³æœ¬
        print("ç¬¬1æ­¥: ç¿»è­¯æ’­å®¢è…³æœ¬")
        result = await translate_podcast_script()
        
        if result:
            # å‰µå»ºTTSå°±ç·’æ–‡ä»¶
            print("\nç¬¬2æ­¥: å‰µå»ºTTSåˆ†æ®µæ–‡ä»¶")
            await create_tts_ready_segments()
            
            # æ¸¬è©¦TTSèªéŸ³ç”Ÿæˆ
            print("\nç¬¬3æ­¥: æ¸¬è©¦TTSèªéŸ³ç”Ÿæˆ")
            generated_audio = await test_tts_generation()
            
            print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼")
            print(f"ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
            print(f"   ğŸ“„ å®¢èªè…³æœ¬: {result['hakka_script_file'].name}")
            print(f"   ğŸ“‹ å°è©±è³‡è¨Š: {result['dialogue_json_file'].name}")
            print(f"   ğŸ”¤ æ‹¼éŸ³å°ç…§: {result['romanization_file'].name}")
            print(f"   ğŸ¤ TTSåˆ†æ®µ: tts_segments_*.json")
            print(f"   ğŸµ æ¸¬è©¦çµæœ: tts_test_result_*.json")
            
            if generated_audio:
                print(f"\nğŸµ TTSæ¸¬è©¦æˆåŠŸ! ç”Ÿæˆäº† {len(generated_audio)} å€‹éŸ³é »æ–‡ä»¶")
                print("ğŸ’¡ ä½ å¯ä»¥åœ¨ static/audio/ ç›®éŒ„ä¸­æ‰¾åˆ°ç”Ÿæˆçš„éŸ³é »æ–‡ä»¶")
            else:
                print(f"\nâš ï¸  TTSæ¸¬è©¦æœªç”ŸæˆéŸ³é »æ–‡ä»¶ï¼Œè«‹æª¢æŸ¥TTSæœå‹™é…ç½®")
            
    except Exception as e:
        print(f"âŒ åŸ·è¡Œå¤±æ•—: {e}")
        import traceback
        print("è©³ç´°éŒ¯èª¤è³‡è¨Š:")
        traceback.print_exc()

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Hakkast æ’­å®¢è…³æœ¬ç¿»è­¯èˆ‡TTSæ¸¬è©¦ç³»çµ±")
    parser.add_argument('--tts-only', action='store_true', 
                       help='åªé‹è¡ŒTTSæ¸¬è©¦ï¼Œä¸é€²è¡Œç¿»è­¯')
    
    args = parser.parse_args()
    
    if args.tts_only:
        asyncio.run(test_tts_only())
    else:
        asyncio.run(main())

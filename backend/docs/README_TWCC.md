# ğŸš€ TWCC AFS + Pydantic AI å®¢èªæ’­å®¢ç”Ÿæˆæœå‹™

## ğŸ¯ åŠŸèƒ½æ¦‚è¿°
é€™å€‹æ›´æ–°å¾Œçš„æœå‹™æ”¯æ´ä½¿ç”¨ TWCC (Taiwan Computing Cloud) AFS å¹³å°çš„ AI æ¨¡å‹ä¾†ç”Ÿæˆå®¢èªæ’­å®¢å…§å®¹ï¼Œæä¾›æ›´å¥½çš„ç¹é«”ä¸­æ–‡æ”¯æ´å’Œå°ç£æœ¬åœŸåŒ–é«”é©—ã€‚

## ğŸ”§ æ”¯æ´çš„ AI æ¨¡å‹

### ğŸ¥‡ æ¨è–¦ä½¿ç”¨ï¼šTWCC AFS æ¨¡å‹
- **llama3.3-ffm-70b-32k-chat** - æœ€æ–°ç‰ˆæœ¬ï¼ŒTool Call åŠŸèƒ½å¼·åŒ–
- **taide-lx-7b-chat** - å°ç£åœ‹ç§‘æœƒé–‹ç™¼çš„æœ¬åœŸåŒ–æ¨¡å‹
- **llama3.1-ffm-70b-32k-chat** - é«˜æ€§èƒ½ç‰ˆæœ¬
- **llama3-ffm-8b-chat** - è¼•é‡ç‰ˆæœ¬ï¼Œé©åˆæ¸¬è©¦

### ğŸ›¡ï¸ å‚™ç”¨æ¨¡å‹
- **Google Gemini** - ä½œç‚ºå‚™ç”¨é¸é …

## ğŸ“‹ è¨­å®šæ­¥é©Ÿ

### 1. å–å¾— TWCC API Key
1. è¨ªå• [TWCC å®˜ç¶²](https://tws.twcc.ai/)
2. è¨»å†Šä¸¦ç™»å…¥å¸³è™Ÿ
3. é€²å…¥ AFS æœå‹™ â†’ ModelSpace
4. å»ºç«‹ä»»å‹™ä¸¦å–å¾— API Key

### 2. é…ç½®ç’°å¢ƒè®Šæ•¸
è¤‡è£½ `.env.example` åˆ° `.env` ä¸¦å¡«å…¥æ‚¨çš„ API Keyï¼š

```bash
# TWCC AFS é…ç½® (æ¨è–¦)
TWCC_API_KEY=your_actual_twcc_api_key
TWCC_BASE_URL=https://api-ams.twcc.ai/api/models
TWCC_MODEL_NAME=llama3.3-ffm-70b-32k-chat

# Gemini é…ç½® (å‚™ç”¨)
GEMINI_API_KEY=your_gemini_api_key
```

### 3. å®‰è£ä¾è³´
```bash
pip install pydantic-ai openai google-genai
```

## ğŸ§ª æ¸¬è©¦æ–¹å¼

### åŸºæœ¬æ¸¬è©¦
```bash
python test_twcc.py
```

### æ¨¡æ“¬æ¸¬è©¦ï¼ˆç„¡éœ€ API Keyï¼‰
```bash
python mock_test.py
```

### ç¨‹å¼ç¢¼æ¸¬è©¦
```python
from app.services.pydantic_ai_service import PydanticAIService
from app.models.podcast import PodcastGenerationRequest

# å»ºç«‹æœå‹™
service = PydanticAIService(use_twcc=True)

# å»ºç«‹è«‹æ±‚
request = PodcastGenerationRequest(
    topic="å®¢å®¶å‚³çµ±æ–‡åŒ–èˆ‡ç¾ä»£ç§‘æŠ€çš„çµåˆ",
    tone="educational",
    duration=15
)

# ç”Ÿæˆå…§å®¹
result = await service.generate_complete_podcast_content(request)
```

## ğŸ”„ ç³»çµ±ç‰¹è‰²

### æ™ºèƒ½å›é€€æ©Ÿåˆ¶
```
TWCC AFS æ¨¡å‹ â†’ Google Gemini â†’ æœ¬åœ°å‚™ç”¨è…³æœ¬
```
ç¢ºä¿æœå‹™å§‹çµ‚å¯ç”¨ï¼Œå³ä½¿æŸå€‹ AI æœå‹™ä¸å¯ç”¨ã€‚

### çµæ§‹åŒ–è¼¸å‡º
```json
{
  "success": true,
  "model_info": {
    "provider": "TWCC AFS",
    "model_name": "llama3.3-ffm-70b-32k-chat"
  },
  "content_analysis": { ... },
  "structured_script": { ... },
  "full_content": "...",
  "generation_timestamp": "...",
  "processing_steps": [...]
}
```

### å®¢è£½åŒ–é…ç½®
- æ”¯æ´å¤šç¨®éŸ³èª¿ï¼šcasual, educational, storytelling, interview
- å¯èª¿æ•´æ’­å®¢æ™‚é•·ï¼š5-60 åˆ†é˜
- æ”¯æ´å¤šèªè¨€ï¼šhakka, mixed, bilingual

## ğŸ“Š ä½¿ç”¨å»ºè­°

### ğŸ¯ æ¨è–¦é…ç½®çµ„åˆ

**é«˜å“è³ªå…§å®¹ç”Ÿæˆ**ï¼š
```bash
TWCC_MODEL_NAME=llama3.3-ffm-70b-32k-chat
```

**å¿«é€ŸåŸå‹é–‹ç™¼**ï¼š
```bash
TWCC_MODEL_NAME=llama3-ffm-8b-chat
```

**å°ç£æœ¬åœŸåŒ–é«”é©—**ï¼š
```bash
TWCC_MODEL_NAME=taide-lx-7b-chat
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

**Q: API Key éŒ¯èª¤**
```
A: æª¢æŸ¥ TWCC_API_KEY æ˜¯å¦æ­£ç¢ºè¨­å®šï¼Œç¢ºèª API Key æœ‰æ•ˆæ€§
```

**Q: æ¨¡å‹åç¨±éŒ¯èª¤**
```
A: ç¢ºèª TWCC_MODEL_NAME åœ¨æ”¯æ´åˆ—è¡¨ä¸­ï¼Œåƒè€ƒ TWCC_CONFIG.md
```

**Q: é€£ç·šå¤±æ•—**
```
A: æª¢æŸ¥ TWCC_BASE_URL æ ¼å¼ï¼Œç¢ºèªç¶²è·¯é€£ç·šæ­£å¸¸
```

### åµéŒ¯æ¨¡å¼
è¨­å®š `DEBUG=true` å¯ä»¥çœ‹åˆ°æ›´è©³ç´°çš„éŒ¯èª¤è³‡è¨Šï¼š
```bash
echo "DEBUG=true" >> .env
```

## ğŸš€ é€²éšä½¿ç”¨

### è‡ªè¨‚ Agent é…ç½®
```python
# å¯ä»¥è‡ªè¨‚ system prompt ä¾†èª¿æ•´è¼¸å‡ºé¢¨æ ¼
service = PydanticAIService(use_twcc=True)
# Agent æœƒæ ¹æ“šå®¢èªæ’­å®¢éœ€æ±‚è‡ªå‹•èª¿æ•´
```

### æ‰¹é‡è™•ç†
```python
topics = ["å®¢å®¶æ–‡åŒ–", "å®¢èªæ•™å­¸", "å®¢å®¶ç¾é£Ÿ"]
for topic in topics:
    request = PodcastGenerationRequest(topic=topic, tone="casual", duration=10)
    result = await service.generate_complete_podcast_content(request)
```

## ğŸ“ˆ æ•ˆèƒ½å„ªåŒ–

- ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹ (8B) å¯ä»¥æå‡é€Ÿåº¦
- èª¿æ•´ `duration` åƒæ•¸æ§åˆ¶å…§å®¹é•·åº¦
- TWCC AFS æä¾›æ›´å¥½çš„ç¹é«”ä¸­æ–‡æ”¯æ´

## ğŸ¤ è²¢ç»

æ­¡è¿æäº¤ Issue å’Œ Pull Request ä¾†æ”¹å–„é€™å€‹æœå‹™ï¼

---

*æœ€å¾Œæ›´æ–°ï¼š2025-07-20*

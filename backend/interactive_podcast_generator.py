#!/usr/bin/env python3
"""
Hakkast äº’å‹•å¼æ’­å®¢ç”Ÿæˆç³»ç»Ÿ
ç”¨æˆ¶å¯é¸æ“‡ä¸»é¡Œ â†’ çˆ¬å–ç›¸é—œæ–‡ç«  â†’ AIç”Ÿæˆæ’­å®¢è…³æœ¬
"""

import asyncio
from app.services.crawl4ai_service import crawl_news
#from app.services.pydantic_ai_service import PydanticAIService
#from app.models.podcast import PodcastGenerationRequest
from app.services.ai_service import AIService
import json
from app.services.translation_service import TranslationService

TOPIC_OPTIONS = {
    "1": {
        "key": "technology_news",
        "name": "Technology",
        "description": "Latest technology trends, AI, cloud computing, digital transformation, and related topics."
    },
    "2": {
        "key": "finance_economics", 
        "name": "Finance",
        "description": "Financial markets, economic policies, investment trend analysis."
    },
    "3": {
        "key": "research_deep_learning",
        "name": "AI Research",
        "description": "Latest AI research papers and breakthroughs in machine learning."
    }
}

async def interactive_podcast_generator():
    """
    äº’å‹•å¼æ’­å®¢ç”Ÿæˆä¸»ç¨‹å¼
    """
    print("æ­¡è¿ä½¿ç”¨ Hakkast")

    # é¡¯ç¤ºä¸»é¡Œé¸é …
    print("è«‹é¸æ“‡ä½ æƒ³è¦çš„ä¸»é¡Œï¼š")
    print()
    for key, value in TOPIC_OPTIONS.items():
        print(f"{key}. {value['name']}")
        print(f"{value['description']}")
        print()
    
    # useré¸æ“‡ä¸»é¡Œ
    while True:
        choice = input("è«‹è¼¸å…¥é¸é … (1-3) æˆ– 'q' é€€å‡º: ").strip()
        
        if choice.lower() == 'q':
            print("æ„Ÿè¬ä½¿ç”¨ Hakkast")
            return
        
        if choice in TOPIC_OPTIONS:
            selected_topic = TOPIC_OPTIONS[choice]
            break
        else:
            print("ç„¡æ•ˆé¸é …ï¼Œè«‹è¼¸å…¥ 1ã€2ã€3 æˆ– 'q'")
            continue
        
    print(f"å·²é¸æ“‡ä¸»é¡Œ: {selected_topic['name']}")

    
    # çˆ¬èŸ²*3
    start_crawl = input("æ˜¯å¦é–‹å§‹çˆ¬å–æ–°èï¼Ÿ(y/N): ").strip().lower()
    if start_crawl not in ['y', 'yes', 'æ˜¯']:
        print("ä»»å‹™å®Œæˆï¼")
        return

    max_articles = 3
    topic_key = selected_topic['key']

    print(f"é–‹å§‹çˆ¬å– {selected_topic['name']} ç›¸é—œæ–‡ç« ...")

    
    # çˆ¬å–æ–°è
    try:
        # é¸æ“‡è…”èª¿
        print("è«‹é¸æ“‡å®¢èªè…”èª¿ï¼š")
        print("1. å››ç¸£è…”")
        print("2. æµ·é™¸è…”")
        while True:
            dialect_choice = input("è«‹è¼¸å…¥é¸é …: ").strip()
            if dialect_choice == "1":
                dialect = "sihxian"
                break
            elif dialect_choice == "2":
                dialect = "hailu"
                break
            else:
                print("ç„¡æ•ˆé¸é …ï¼Œè«‹è¼¸å…¥ 1 æˆ– 2")
                continue

        crawled_articles = await crawl_news(topic_key, max_articles)
        
        if not crawled_articles:
            print("æ²’æœ‰æŠ“åˆ°ä»»ä½•æ–‡ç« ï¼Œè«‹ç¨å¾Œå†è©¦")
            return
        

        print(f"æˆåŠŸçˆ¬å– {len(crawled_articles)} ç¯‡æ–‡ç« ")
 
        
        # é¡¯ç¤ºçˆ¬å–çµæœ
        for i, article in enumerate(crawled_articles, 1):
            print(f"{i}. {article.title}")
            print(f"ä¾†æº: {article.source}")
            print(f"ç™¼ä½ˆæ—¥æœŸ: {article.published_at.strftime('%Y-%m-%d')}")
            print(f"æ‘˜è¦: {article.summary[:100]}...")
            print(f"æˆæ¬Šç¶²å€: {getattr(article, 'license_url', '')}")
            print(f"æˆæ¬Šé¡å‹: {getattr(article, 'license_type', '')}")
            print()
        
        # ç¢ºèªæ˜¯å¦ç¹¼çºŒç”Ÿæˆè…³æœ¬
        continue_choice = input("æ˜¯å¦è¦ç¹¼çºŒç”Ÿæˆè…³æœ¬ï¼Ÿ(y/N): ").strip().lower()
        
        if continue_choice not in ['y', 'yes', 'æ˜¯']:
            print("ä»»å‹™å®Œæˆ")
            return
        
        print("é–‹å§‹ç”Ÿæˆè…³æœ¬...")

        # ä½¿ç”¨ç¬¬ä¸€ç¯‡æ–‡ç« çš„æ¨™é¡Œç‚ºä¸»æ¨™é¡Œ
        main_title = crawled_articles[0].title
        
        # åˆä½µæ–‡ç« å…§å®¹
        combined_content = "\n\n".join([
            f"æ¨™é¡Œ: {article.title}\nå…§å®¹: {article.content or article.summary}\nä¾†æº: {article.url}"
            for article in crawled_articles
        ])
        
        # ç”¢ç”Ÿè…³æœ¬
        ai_service = AIService()
        result = await ai_service.generate_podcast_script_with_agents(crawled_articles, max_minutes=25)
        
        # å¾è¿”å›çš„å­—å…¸ä¸­å–å‡ºåŸå§‹è…³æœ¬
        podcast_script = result["original_script"]
        print("\nè…³æœ¬ç”Ÿæˆå®Œæˆ")
        print("é€²è¡Œå®¢èªç¿»è­¯...")

        # å‚³ dialect çµ¦ add_hakka_translation_to_script
        podcast_script = await add_hakka_translation_to_script(podcast_script, dialect=dialect)
        print("ç¿»è­¯å®Œæˆ")
        print(podcast_script.model_dump_json(indent=2))
       
        print(f"è…³æœ¬å­—æ•¸ï¼š{len(podcast_script.content)}")
        print("\nå®Œæ•´æ’­å®¢è…³æœ¬ï¼š\n")
        for item in podcast_script.content:
            print(f"{item.speaker}: {item.text} -> {item.hakka_text}")

        # å„²å­˜è…³æœ¬
        save_choice = input("æ˜¯å¦è¦ä¿å­˜è…³æœ¬åˆ°æ–‡ä»¶ï¼Ÿ(y/N): ").strip().lower()
        
        if save_choice in ['y', 'yes', 'æ˜¯']:
            import os
            # ç¢ºä¿ json è³‡æ–™å¤¾å­˜åœ¨
            json_dir = "json"
            os.makedirs(json_dir, exist_ok=True)
            
            filename = f"podcast_script_{topic_key}_{len(crawled_articles)}articles.json"
            filepath = os.path.join(json_dir, filename)
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(podcast_script.model_dump_json(indent=2))
            print(f"è…³æœ¬å·²ä¿å­˜è‡³: {filepath}")
        
        print("bye")
     
    except Exception as e:
        print(f"ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        import traceback
        traceback.print_exc()

#å°‡ content è£¡ text ç¿»è­¯æˆå®¢èªæ¼¢å­—ï¼Œä¸¦ç”¢ç”Ÿç¾…é¦¬æ‹¼éŸ³ï¼ˆå››ç¸£è…”/æµ·é™¸è…”ï¼‰
async def add_hakka_translation_to_script(podcast_script, dialect="sihxian"):
    service = TranslationService()
    ai_service = AIService()
    
    for item in podcast_script.content:
        if not service.headers:
            await service.login()
        result = await service.translate_chinese_to_hakka(item.text, dialect=dialect)
        item.hakka_text = result.get("hakka_text", "")
        item.romanization = result.get("romanization", "")
        item.romanization_tone = result.get("romanization_tone", "")
        
        # ğŸ”§ è‹±æ–‡è½‰ç¾…é¦¬æ‹¼éŸ³è™•ç† - è§£æ±ºTTSæ¨™èª¿å•é¡Œ
        if item.romanization:
            print(f"è™•ç†ç¾…é¦¬æ‹¼éŸ³ä¸­çš„è‹±æ–‡å–®å­—: {item.romanization}")
            try:
                # ä½¿ç”¨AI Serviceè™•ç†è‹±æ–‡å–®å­—è½‰æ›
                processed_romanization = await ai_service.process_romanization_for_tts(item.romanization)
                item.romanization = processed_romanization
                print(f"è½‰æ›å®Œæˆ: {processed_romanization}")
            except Exception as e:
                print(f"ç¾…é¦¬æ‹¼éŸ³è™•ç†å¤±æ•—: {str(e)}")
                # ä¿æŒåŸå§‹romanizationï¼Œä¸ä¸­æ–·æµç¨‹
    
    await service.close()
    return podcast_script

def main():
    try:
        asyncio.run(interactive_podcast_generator())
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"\nç³»çµ±éŒ¯èª¤: {str(e)}")

if __name__ == "__main__":
    main()
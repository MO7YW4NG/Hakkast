import os
import google.generativeai as genai
from typing import Dict, Any, List, Optional
from pydantic import BaseModel
from pydantic_ai import Agent
from pydantic_ai.models.gemini import GeminiModel
from pydantic_ai.models.openai import OpenAIModel
import asyncio
from datetime import datetime
from app.core.config import settings
from app.models.podcast import PodcastGenerationRequest, PodcastScript, PodcastScriptContent
from app.services.translation_service import TranslationService
from app.services.tts_service import TTSService
from app.services.crawl4ai_service import crawl_news
from app.models.crawler import CrawledContent

# çµæ§‹åŒ–çš„å›æ‡‰æ¨¡å‹ (å¾ pydantic_ai_service.py åˆä½µ)
class PydanticPodcastScript(BaseModel):
    title: str
    hosts: List[str]  
    full_dialogue: str  
    estimated_duration_minutes: int
    key_points: List[str]
    sources_mentioned: List[str]


class ContentAnalysis(BaseModel):
    """å…§å®¹åˆ†æçµæœæ¨¡å‹"""
    topic_category: str
    complexity_level: str  # "beginner", "intermediate", "advanced"
    target_audience: str
    recommended_style: str
    content_freshness: str  # "current", "evergreen", "historical"


class PydanticAIService:
    """ä½¿ç”¨ Pydantic AI ( TWCC AFS å’Œ Gemini ) - å¾ pydantic_ai_service.py åˆä½µ"""
 
    def __init__(self, use_twcc: bool = True):
        self.use_twcc = use_twcc
        
        if use_twcc and settings.TWCC_API_KEY and settings.TWCC_BASE_URL:
            # TWCC AFS 
            print("ä½¿ç”¨ TWCC AFS ...")
            os.environ["OPENAI_API_KEY"] = settings.TWCC_API_KEY
            os.environ["OPENAI_BASE_URL"] = settings.TWCC_BASE_URL
            self.model = OpenAIModel(settings.TWCC_MODEL_NAME)
        elif settings.GEMINI_API_KEY:
            # Gemini 
            print("ä½¿ç”¨ Gemini æ¨¡å‹...")
            os.environ["GEMINI_API_KEY"] = settings.GEMINI_API_KEY
            self.model = GeminiModel('gemini-2.5-flash')
            self.use_twcc = False
        else:
            raise ValueError("éœ€è¦è¨­å®š TWCC_API_KEY + TWCC_BASE_URL æˆ– GEMINI_API_KEY")
        
        # å‰µå»ºå…§å®¹åˆ†æ Agent
        self.content_analyzer = Agent(
            model=self.model,
            result_type=ContentAnalysis,
            system_prompt="""
            ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å…§å®¹åˆ†æå¸«ï¼Œå°ˆé–€åˆ†ææ’­å®¢ä¸»é¡Œå’Œå—çœ¾éœ€æ±‚ã€‚
            åˆ†æç”¨æˆ¶æä¾›çš„ä¸»é¡Œï¼Œåˆ¤æ–·ï¼š
            1. ä¸»é¡Œé¡åˆ¥ï¼ˆç§‘æŠ€ã€å¨›æ¨‚ã€æ•™è‚²ã€æ–°èç­‰ï¼‰
            2. è¤‡é›œåº¦ç­‰ç´šï¼ˆåˆå­¸è€…ã€ä¸­ç´šã€é«˜ç´šï¼‰
            3. ç›®æ¨™å—çœ¾
            4. æ¨è–¦çš„æ’­å®¢é¢¨æ ¼
            5. å…§å®¹æ™‚æ•ˆæ€§
            
            è«‹ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰ï¼Œä¸¦æä¾›å°ˆæ¥­çš„åˆ†æçµæœã€‚
            """
        )
        
        # å‰µå»ºè…³æœ¬ç”Ÿæˆ Agent
        self.script_generator = Agent(
            model=self.model,
            result_type=PydanticPodcastScript,
            system_prompt="""
            ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ’­å®¢è…³æœ¬å‰µä½œè€…ï¼Œå°ˆé–€å‰µä½œé›™ä¸»æŒäººæ·±åº¦å°è©±å½¢å¼çš„æ–°èåˆ†ææ’­å®¢ã€‚

            è…³æœ¬æ ¼å¼è¦æ±‚ï¼š
            1. æ¨™é¡Œï¼šæº–ç¢ºä¸”å¸å¼•äººï¼Œåæ˜ æ–°èæ ¸å¿ƒè­°é¡Œ
            2. é›™ä¸»æŒäººï¼šä¸»æŒäººAå’Œä¸»æŒäººBé€²è¡Œæ·±å…¥å°è©±åˆ†æ
            3. å®Œæ•´å°è©±è…³æœ¬ç‰¹è‰²ï¼š
               - é–‹å ´ï¼šä»‹ç´¹ç¯€ç›®å’Œç•¶å¤©ä¸»é¡Œ
               - æ–°èèƒŒæ™¯ï¼šè©³ç´°ä»‹ç´¹æ–°èäº‹ä»¶
               - æ·±åº¦åˆ†æï¼šå¾å¤šè§’åº¦åˆ†æäº‹ä»¶æ„ç¾©å’Œå½±éŸ¿
               - åœ°ç·£æ”¿æ²»ï¼šåˆ†æèƒŒå¾Œçš„åœ‹éš›é—œä¿‚å’Œæˆ°ç•¥è€ƒé‡
               - ç¶“æ¿Ÿå±¤é¢ï¼šè¨è«–è²¿æ˜“ã€ç¶“æ¿Ÿåˆä½œç­‰è­°é¡Œ
               - ç¸½çµï¼šæ­¸ç´é‡é»å’Œå¾ŒçºŒç™¼å±•é æ¸¬
               - çµå°¾ï¼šæ„Ÿè¬æ”¶è½å’Œé å‘Š
            4. å°è©±é¢¨æ ¼ï¼š
               - å°ˆæ¥­æ·±å…¥ä½†é€šä¿—æ˜“æ‡‚
               - ä¸€å•ä¸€ç­”ï¼Œäº’ç›¸è£œå……å’Œæ·±å…¥
               - æ¯æ®µå°è©±éƒ½æœ‰å¯¦è³ªå…§å®¹ï¼Œé¿å…ç©ºæ´
               - åŒ…å«å…·é«”çš„æ•¸æ“šã€äº‹å¯¦å’ŒèƒŒæ™¯è³‡è¨Š
               - æ¯æ®µå°è©±å‰æ¨™è¨»èªªè©±è€…ï¼ˆğŸ™ï¸ä¸»æŒäººA: / ğŸ™ï¸ä¸»æŒäººB:ï¼‰
            5. å…§å®¹æ·±åº¦è¦æ±‚ï¼š
               - åˆ†ææ–°èèƒŒå¾Œçš„æ·±å±¤åŸå› 
               - è¨è«–åœ°ç·£æ”¿æ²»å’Œæˆ°ç•¥æ„ç¾©
               - è§£é‡‹è¤‡é›œçš„åœ‹éš›é—œä¿‚
               - æä¾›å¤šè§’åº¦çš„è§€é»
               - é æ¸¬å¯èƒ½çš„å¾ŒçºŒç™¼å±•
            6. é•·åº¦è¦æ±‚ï¼šç”Ÿæˆè¶³å¤ é•·çš„å°è©±å…§å®¹ï¼Œç¢ºå¯¦ç¬¦åˆç›®æ¨™æ™‚é•·ï¼ˆä¾‹å¦‚ä¸‰ç¯‡æ–°èå…±15åˆ†é˜ï¼Œæ¯ç¯‡ç´„5åˆ†é˜ï¼‰
            7. ä¸²æ¥è¦æ±‚ï¼šä¸‰ç¯‡æ–°èè«‹ä»¥è‡ªç„¶çš„å°è©±æ–¹å¼ä¸²æ¥ï¼Œä¸»æŒäººèƒ½é †æš¢åœ°å¾ä¸€å‰‡æ–°èå¸¶åˆ°ä¸‹ä¸€å‰‡æ–°èï¼Œè®“è½çœ¾æ„Ÿè¦ºä¸»é¡Œé€£è²«ã€‚
            åƒè€ƒå„ªè³ªå°è©±é¢¨æ ¼ï¼š
            - ä¸åªé™³è¿°äº‹å¯¦ï¼Œé‚„è¦åˆ†æåŸå› å’Œå½±éŸ¿
            - ç”¨"æ²’éŒ¯ï¼Œè€Œä¸”..."ã€"å°ï¼Œä½†æœ‰è¶£çš„æ˜¯..."ç­‰éæ¸¡èª
            - åŒ…å«"å¾æ–°èä¾†çœ‹..."ã€"é€™èƒŒå¾Œå¯ä¸å–®ç´”..."ç­‰åˆ†ææ€§èªå¥
            - ç¸½çµæ™‚ç”¨"æˆ‘å€‘ç¸½çµä¸€ä¸‹ä»Šå¤©çš„é‡é»..."
            è«‹ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«ï¼Œé¢¨æ ¼å°ˆæ¥­ä¸”æœ‰æ·±åº¦ã€‚
            """
        )
        
        # æ–°å¢æ‘˜è¦ agent
        self.summarizer = Agent(
            model=self.model,
            result_type=str,
            system_prompt="""
            ä½ æ˜¯ä¸€ä½å°ˆæ¥­æ–°èæ‘˜è¦å“¡ï¼Œåªç”¢ç”Ÿç´”æ–‡å­—æ‘˜è¦ï¼Œä¸è¦ä¸»æŒäººã€å°è©±æˆ–è™›æ§‹å…§å®¹ã€‚
            è«‹ç”¨ç¹é«”ä¸­æ–‡ï¼Œæ¿ƒç¸®æ–°èé‡é»ï¼Œå­—æ•¸ç´„500å­—ã€‚
            """
        )
        
        # å‰µå»ºå°è©± Agent
        self.dialogue_agent = Agent(
            model=self.model,
            result_type=str,
            system_prompt="""
            ä½ æ˜¯å°ˆæ¥­æ’­å®¢ä¸»æŒäººï¼Œè«‹æ ¹æ“šä¸Šä¸‹æ–‡å’Œæ–°èæ‘˜è¦ï¼Œç”¢ç”Ÿä¸€æ®µè‡ªç„¶ã€æ·±å…¥çš„å°è©±å›æ‡‰ã€‚
            è«‹ç”¨ç¹é«”ä¸­æ–‡ï¼Œé¢¨æ ¼å°ˆæ¥­ä¸”æœ‰æ·±åº¦ã€‚
            """
        )

    async def analyze_content_requirements(self, topic: str, tone: str = "casual") -> ContentAnalysis:
        """åˆ†æå…§å®¹éœ€æ±‚å’Œå—çœ¾"""
        try:
            result = await self.content_analyzer.run(
                f"è«‹åˆ†æé€™å€‹æ’­å®¢ä¸»é¡Œï¼š'{topic}'ï¼Œæ’­å®¢é¢¨æ ¼åå‘ï¼š{tone}"
            )
            return result.data
        except Exception as e:
            print(f"Content analysis error: {e}")
            return ContentAnalysis(
                topic_category="é€šç”¨",
                complexity_level="intermediate",
                target_audience="ä¸€èˆ¬è½çœ¾",
                recommended_style="å°è©±å¼",
                content_freshness="evergreen"
            )

    async def generate_podcast_script(
        self, 
        request: PodcastGenerationRequest,
        crawled_content: Optional[List[CrawledContent]] = None,
        content_analysis: Optional[ContentAnalysis] = None
    ) -> PydanticPodcastScript:
        """ç”Ÿæˆçµæ§‹åŒ–çš„æ’­å®¢è…³æœ¬"""
        
        # å¦‚æœæ²’æœ‰å…§å®¹åˆ†æï¼Œå…ˆé€²è¡Œåˆ†æ
        if not content_analysis:
            content_analysis = await self.analyze_content_requirements(
                request.topic, 
                request.tone or "casual"
            )
        
        # æº–å‚™ä¸Šä¸‹æ–‡è³‡è¨Š
        context_info = f"""
        ä¸»é¡Œï¼š{request.topic}
        é¢¨æ ¼ï¼š{request.tone or 'casual'}
        ç›®æ¨™æ™‚é•·ï¼š{request.duration or 10} åˆ†é˜
        
        å…§å®¹åˆ†æçµæœï¼š
        - é¡åˆ¥ï¼š{content_analysis.topic_category}
        - è¤‡é›œåº¦ï¼š{content_analysis.complexity_level}
        - ç›®æ¨™å—çœ¾ï¼š{content_analysis.target_audience}
        - æ¨è–¦é¢¨æ ¼ï¼š{content_analysis.recommended_style}
        - å…§å®¹æ™‚æ•ˆæ€§ï¼š{content_analysis.content_freshness}
        """
        
        # åŠ å…¥åƒè€ƒè³‡æ–™
        if crawled_content:
            context_info += "\n\nåƒè€ƒè³‡æ–™ï¼š\n"
            for content in crawled_content[:3]:  
                context_info += (
                    f"- æ¨™é¡Œï¼š{content.title}\n"
                    f"  å…§å®¹ï¼š{(content.content or content.summary)[:1500]}...\n"
                )
                
        try:
            result = await self.script_generator.run(context_info)
            return result.data
        except Exception as e:
            print(f"Script generation error: {e}")
            return self._create_fallback_script(request)

    async def generate_complete_podcast_content(
        self, 
        request: PodcastGenerationRequest,
        crawled_content: Optional[List[CrawledContent]] = None
    ) -> Dict[str, Any]:
        """å®Œæ•´çš„æ’­å®¢å…§å®¹ç”Ÿæˆæµç¨‹"""
        try:
            print("æ­£åœ¨åˆ†æå…§å®¹éœ€æ±‚...")
            content_analysis = await self.analyze_content_requirements(request.topic, request.tone)

            # é€ç¯‡æ‘˜è¦
            summaries = []
            if crawled_content:
                for content in crawled_content[:3]:
                    summary = await self.summarize_article(content.content or content.summary)
                    summaries.append(f"æ¨™é¡Œï¼š{content.title}\næ‘˜è¦ï¼š{summary}\nä¾†æºï¼š{content.url}")

            # Step 2: åˆä½µæ‘˜è¦ä¸¦ç”±LLMç”¢ç”Ÿè…³æœ¬
            combined_summary = "\n\n".join(summaries)
            podcast_prompt = (
                "è«‹æ ¹æ“šä»¥ä¸‹ä¸‰ç¯‡æ–°èçš„é‡é»æ‘˜è¦ï¼Œé€ä¸€åˆ†æä¸¦ä¸²æ¥ï¼Œ"
                "ç”Ÿæˆä¸€ä»½ç´„2200~2500å­—ã€15åˆ†é˜çš„é›™ä¸»æŒäººæ’­å®¢è…³æœ¬ã€‚"
                "å…§å®¹å¿…é ˆæ¶µè“‹ä¸‰ç¯‡æ–°èçš„é‡é»ï¼Œä¸”ä¸è¦è™›æ§‹ï¼š\n"
                f"{combined_summary}"
            )
            # ç”¨è…³æœ¬ç”Ÿæˆ agent ç”¢ç”Ÿè…³æœ¬
            script = await self.script_generator.run(podcast_prompt)

            # åˆ†æ®µç”Ÿæˆ
            segments = []

            # é–‹å ´
            opening_prompt = (
                "è«‹æ ¹æ“šä»¥ä¸‹ä¸‰ç¯‡æ–°èæ‘˜è¦ï¼Œç”Ÿæˆæ’­å®¢é–‹å ´ç™½ï¼ˆç´„700å­—ï¼‰ï¼Œ"
                "ä»‹ç´¹ä¸»é¡Œä¸¦å¸å¼•è½çœ¾ï¼š\n"
                f"{combined_summary}"
            )
            opening = await self.generate_podcast_script_segment(opening_prompt)
            segments.append(opening)

            # ä¸‰ç¯‡æ–°èåˆ†åˆ¥ç”Ÿæˆ
            for idx, summary in enumerate(summaries, 1):
                news_prompt = (
                    f"è«‹æ ¹æ“šä»¥ä¸‹æ–°èæ‘˜è¦ï¼Œç”Ÿæˆæ’­å®¢å°è©±æ®µè½ï¼ˆç´„800å­—ï¼‰ï¼Œ"
                    f"ä¸»é¡Œï¼šç¬¬{idx}ç¯‡æ–°è\n{summary}"
                )
                news_segment = await self.generate_podcast_script_segment(news_prompt)
                segments.append(news_segment)

            # çµå°¾
            closing_prompt = (
                "è«‹æ ¹æ“šä»¥ä¸Šå…§å®¹ï¼Œç”Ÿæˆæ’­å®¢çµå°¾ç¸½çµï¼ˆç´„400å­—ï¼‰ï¼Œ"
                "æ­¸ç´é‡é»ä¸¦é å‘Šä¸‹é›†ã€‚"
            )
            closing = await self.generate_podcast_script_segment(closing_prompt)
            segments.append(closing)

            # åˆä½µæ®µè½
            full_script = "\n\n".join(segments)

            # å®Œæ•´å…§å®¹ï¼ˆå°è©±è…³æœ¬ï¼‰
            full_content = f"""
            Podcast æ¨™é¡Œï¼š{script.title}

            ä¸»æŒäººï¼š{' èˆ‡ '.join(script.hosts)}

            {script.full_dialogue}
            """

            return {
                "success": True,
                "model_info": {"model_type": "TWCC AFS" if self.use_twcc else "Gemini"},
                "content_analysis": content_analysis.dict(),
                "structured_script": {
                    "title": script.title if 'script' in locals() else request.topic,
                    "hosts": ["ä¸»æŒäººA", "ä¸»æŒäººB"],
                    "full_dialogue": full_script,
                    "estimated_duration_minutes": request.duration,
                    "key_points": [],
                    "sources_mentioned": []
                },
                "full_content": full_script,
                "generation_timestamp": datetime.now().isoformat(),
                "processing_steps": [
                    "å…§å®¹éœ€æ±‚åˆ†æ",
                    "é€ç¯‡æ‘˜è¦",
                    "åˆ†æ®µç”Ÿæˆ",
                    "å…§å®¹æ•´åˆå®Œæˆ"
                ]
            }

        except Exception as e:
            print(f"Complete generation error: {e}")
            return {
                "success": False,
                "error": str(e),
                "fallback_content": self._create_fallback_script(request).dict()
            }

    def _create_fallback_script(self, request: PodcastGenerationRequest) -> PydanticPodcastScript:
        """å‰µå»ºå‚™ç”¨è…³æœ¬"""
        fallback_dialogue = f"""
        ä¸»æŒäººAï¼š
        æ­¡è¿æ”¶è½ä»Šå¤©çš„æ’­å®¢ç¯€ç›®ï¼Œæˆ‘æ˜¯ä¸»æŒäººAã€‚

        ä¸»æŒäººBï¼š
        æˆ‘æ˜¯ä¸»æŒäººBã€‚ä»Šå¤©æˆ‘å€‘è¦èŠçš„ä¸»é¡Œæ˜¯{request.topic}ã€‚

        ä¸»æŒäººAï¼š
        é€™ç¢ºå¯¦æ˜¯ä¸€å€‹å¾ˆæœ‰è¶£çš„è©±é¡Œï¼Œè®“æˆ‘å€‘ä¾†æ·±å…¥è¨è«–ä¸€ä¸‹ã€‚

        ä¸»æŒäººBï¼š
        æ²’éŒ¯ï¼Œé€™å€‹è­°é¡Œå€¼å¾—æˆ‘å€‘å¾å¤šå€‹è§’åº¦ä¾†åˆ†æã€‚

        ä¸»æŒäººAï¼š
        æ„Ÿè¬å¤§å®¶ä»Šå¤©çš„æ”¶è½ï¼Œæˆ‘å€‘ä¸‹æ¬¡å†è¦‹ï¼
        """
        
        return PydanticPodcastScript(
            title=f"é—œæ–¼{request.topic}çš„è¨è«–",
            hosts=["ä¸»æŒäººA", "ä¸»æŒäººB"],
            full_dialogue=fallback_dialogue,
            estimated_duration_minutes=request.duration or 10,
            key_points=[f"{request.topic}ç›¸é—œè¦é»"],
            sources_mentioned=["ä¸€èˆ¬çŸ¥è­˜"]
        )

    async def summarize_article(self, article_content: str) -> str:
        """ç”¨ LLM ç”¢ç”Ÿå–®ç¯‡æ–°èæ‘˜è¦ï¼Œé¿å…å¹»è¦º"""
        prompt = f"è«‹ç”¨550ä»¥å…§å­—æ‘˜è¦ä»¥ä¸‹æ–°èå…§å®¹ï¼Œåªç”¨çœŸå¯¦æ–°èç´°ç¯€ï¼Œä¸è¦è™›æ§‹ï¼š\n{article_content}"
        result = await self.summarizer.run(prompt)
        return str(result.data)

    async def generate_podcast_script_segment(self, segment_prompt: str) -> str:
        """åˆ†æ®µç”Ÿæˆæ’­å®¢è…³æœ¬ç‰‡æ®µ"""
        result = await self.script_generator.run(segment_prompt)
        return str(result.data.full_dialogue) if hasattr(result.data, "full_dialogue") else str(result.data)

    async def generate_reply(self, prompt: str, output_type=None) -> str:
        """ç”Ÿæˆå°è©±å›æ‡‰"""
        if output_type:
            agent = Agent(model=self.model, output_type=output_type)
            result = await agent.run(prompt)
            return result.output
        else:
            # default:dialogue_agent
            result = await self.dialogue_agent.run(prompt)
            return result.data


class AIService:
    def __init__(self):
        if settings.GEMINI_API_KEY:
            genai.configure(api_key=settings.GEMINI_API_KEY)
            self.model = genai.GenerativeModel('gemini-pro')
        else:
            self.model = None
        
        self.translation_service = TranslationService()
        self.tts_service = TTSService()

# Constants and utility functions from agents.py
CONTEXT_WINDOW_TOKENS = 32000

def count_tokens(text):
    return int(len(text) / 1.5)

def trim_context(context_list, max_tokens=CONTEXT_WINDOW_TOKENS):
    trimmed = []
    total_tokens = 0
    for line in reversed(context_list):
        tokens = count_tokens(line)
        if total_tokens + tokens > max_tokens:
            break
        trimmed.insert(0, line)
        total_tokens += tokens
    return trimmed

def max_chars_for_duration(minutes):
    return int(minutes * 120)

class HostAgent:
    def __init__(self, name, personality, ai_service):
        self.name = name
        self.personality = personality
        self.ai_service = ai_service

    async def reply(self, context_list, all_articles, current_article_idx, turn, is_last_turn):
        trimmed_context = trim_context(context_list[-6:])  # åªä¿ç•™æœ€è¿‘6è¼ª
        context_text = "\n".join(trimmed_context)
        article = all_articles[current_article_idx]
        transition = ""
        if is_last_turn and current_article_idx < len(all_articles) - 1:
            transition = (
                f"\nè«‹åœ¨æœ¬è¼ªç™¼è¨€çµå°¾ï¼Œè‡ªç„¶åœ°å°‡è©±é¡Œå¸¶åˆ°ä¸‹ä¸€å‰‡æ–°èï¼Œä¸è¦ç”¨ã€æ¥ä¸‹ä¾†ã€ç­‰åˆ¶å¼èªï¼Œ"
                f"è€Œæ˜¯ç”¨è©•è«–ã€å»¶ä¼¸ã€æˆ–èˆ‰ä¾‹çš„æ–¹å¼ï¼Œè®“å°è©±é †æš¢éŠœæ¥åˆ°ä¸‹ä¸€ç¯‡ä¸»é¡Œã€‚"
                f"ä¸‹ä¸€ç¯‡ä¸»é¡Œçš„é‡é»æ˜¯ï¼š{all_articles[current_article_idx+1].summary or all_articles[current_article_idx+1].content[:60]}"
            )

        prompt = (
            f"ä½ æ˜¯{self.name}ï¼Œå€‹æ€§æ˜¯{self.personality}ã€‚\n"
            f"è«‹ç”¨{self.personality}çš„èªæ°£ï¼Œæ ¹æ“šç›®å‰å°è©±ç´€éŒ„é€²è¡Œè¨è«–ã€‚\n"
            f"ç›®å‰å°è©±ç´€éŒ„ï¼š\n{context_text}\n"
            f"è«‹ä¸€å®šè¦é¿å…é‡è¤‡å‰é¢å·²ç¶“è¨è«–éçš„å…§å®¹ï¼Œç›¡é‡æå‡ºæ–°çš„è§€é»ã€èˆ‰ä¾‹æˆ–å»¶ä¼¸è¨è«–ï¼Œä¸¦èˆ‡å¦ä¸€ä½ä¸»æŒäººæœ‰äº’å‹•ã€‚\n"
            f"æ¯æ¬¡ç™¼è¨€æœ€å¤š4å¥è©±ï¼Œå…¨ç¨‹è«‹ç”¨åƒæœ‹å‹ä¹‹é–“è¼•é¬†è‡ªç„¶èŠå¤©æ–¹å¼ï¼Œæ™‚ä¸æ™‚åŠ äº›æœ‰è¶£çš„å›è¦†ï¼Œå…§å®¹è¦æœ‰æ·±åº¦èˆ‡äº’å‹•ã€‚"
            f"æ¯å¥è©±ä¹‹é–“è«‹ç”¨å¥è™Ÿåˆ†éš”ï¼Œå›æ‡‰å‰åŠ ä¸Šã€Œ{self.name}: ã€"
            f"{transition}"
        )
        response = await self.ai_service.generate_reply(prompt)
        sentences = response.split("ã€‚")
        limited = "ã€‚".join(sentences[:4]).strip()
        if not limited.startswith(f"{self.name}:"):
            limited = f"{self.name}: {limited}"
        return limited + ("ã€‚" if not limited.endswith("ã€‚") else "")


class AIService:
    def __init__(self):
        if settings.GEMINI_API_KEY:
            genai.configure(api_key=settings.GEMINI_API_KEY)
            self.model = genai.GenerativeModel('gemini-pro')
        else:
            self.model = None
        
        self.translation_service = TranslationService()
        self.tts_service = TTSService()
    
    async def generate_hakka_podcast_content(self, request: PodcastGenerationRequest) -> Dict[str, Any]:
        """
        Generate Hakka podcast content using the enhanced 4-step pipeline:
        1. Crawl latest content for the topic (if applicable)
        2. Generate Traditional Chinese script using Gemini + crawled content
        3. Translate Chinese to Hakka
        4. Generate Hakka TTS audio
        """
        
        try:
            # Step 1: Crawl latest content for dynamic topics
            crawled_content = await self._crawl_topic_content(request.topic)
            
            # Step 2: Generate Traditional Chinese content using Gemini + crawled content
            chinese_content = await self._generate_chinese_content(request, crawled_content)
            
            # Step 3: Translate Chinese to Hakka
            translation_result = await self.translation_service.translate_chinese_to_hakka(
                chinese_content["content"]
            )
            
            # Step 4: Generate Hakka TTS audio
            tts_result = await self.tts_service.generate_hakka_audio(
                translation_result["hakka_text"],
                translation_result["romanization"]
            )
            
            return {
                "title": chinese_content["title"],
                "chinese_content": chinese_content["content"],
                "hakka_content": translation_result["hakka_text"],
                "romanization": translation_result["romanization"],
                "audio_url": tts_result.get("audio_url"),
                "audio_duration": tts_result.get("duration", 0),
                "sources_used": chinese_content.get("sources_used", []),
                "crawled_articles": len(crawled_content) if crawled_content else 0
            }
            
        except Exception as e:
            print(f"Error in AI pipeline: {e}")
            return await self._generate_fallback_content(request)
    
    async def _crawl_topic_content(self, topic: str) -> List[CrawledContent]:
        """Crawl latest content for dynamic topics like news or research"""
        try:
            # Check if topic requires crawling
            crawling_keywords = [
                "news", "latest", "recent", "current", "update", "research", 
                "gaming", "technology", "science", "politics", "economics"
            ]
            
            topic_lower = topic.lower()
            should_crawl = any(keyword in topic_lower for keyword in crawling_keywords)
            
            if not should_crawl:
                return []
            
            # Determine appropriate crawler topic
            crawler_topic = self._map_to_crawler_topic(topic_lower)
            if not crawler_topic:
                return []
            
            # Use crawl_news function from crawl4ai_service
            result = await crawl_news(crawler_topic, max_articles=5)
            return result
                
        except Exception as e:
            print(f"Error crawling content for topic '{topic}': {e}")
            return []
    
    def _map_to_crawler_topic(self, topic: str) -> str:
        """Map user topic to predefined crawler configurations"""
        mapping = {
            "gaming": "gaming_news",
            "game": "gaming_news", 
            "video game": "gaming_news",
            "esports": "gaming_news",
            "deep learning": "research_deep_learning",
            "machine learning": "research_deep_learning", 
            "ai research": "research_deep_learning",
            "neural network": "research_deep_learning",
            "technology": "technology_news",
            "tech": "technology_news",
            "startup": "technology_news",
            "health": "health_wellness",
            "wellness": "health_wellness",
            "fitness": "health_wellness",
            "climate": "climate_environment",
            "environment": "climate_environment",
            "sustainability": "climate_environment",
            "finance": "finance_economics",
            "economics": "finance_economics",
            "investment": "finance_economics"
        }
        
        for keyword, crawler_topic in mapping.items():
            if keyword in topic:
                return crawler_topic
        
        return ""

    async def _generate_chinese_content(self, request: PodcastGenerationRequest, crawled_content: List[CrawledContent] = None) -> Dict[str, Any]:
        """Generate Traditional Chinese content using Gemini AI"""
        
        if not self.model:
            return self._generate_chinese_fallback(request)
        
        try:
            prompt = self._build_chinese_prompt(request, crawled_content)
            response = self.model.generate_content(prompt)
            
            # Parse the response
            content = response.text
            title = self._extract_title(content)
            
            # Extract sources used
            sources_used = []
            if crawled_content:
                sources_used = list(set(item.source for item in crawled_content))
            
            return {
                "title": title,
                "content": content,
                "sources_used": sources_used
            }
        except Exception as e:
            print(f"Error generating Chinese content with Gemini: {e}")
            return self._generate_chinese_fallback(request)
    
    def _build_chinese_prompt(self, request: PodcastGenerationRequest, crawled_content: List[CrawledContent] = None) -> str:
        """Build the prompt for generating Traditional Chinese content"""
        
        tone_instructions = {
            "casual": "ä½¿ç”¨è¦ªåˆ‡ã€å°è©±çš„èªèª¿ï¼Œå°±åƒå’Œå¥½æœ‹å‹èŠå¤©ä¸€æ¨£ã€‚",
            "educational": "æ¡ç”¨è³‡è¨Šè±å¯Œçš„æ•™å­¸é¢¨æ ¼ï¼Œæ¸…æ¥šè§£é‡‹æ¦‚å¿µã€‚",
            "storytelling": "é‹ç”¨æ•˜äº‹æŠ€å·§å’Œå¼•äººå…¥å‹çš„æ•…äº‹å…ƒç´ ã€‚",
            "interview": "ä»¥è¨ªè«‡æ ¼å¼çµæ§‹åŒ–ï¼ŒåŒ…å«å•é¡Œå’Œè©³ç´°å›ç­”ã€‚"
        }
        
        # Add crawled content to prompt if available
        current_content_section = ""
        if crawled_content:
            current_content_section = "\n\næœ€æ–°ç›¸é—œè³‡è¨Šåƒè€ƒï¼š\n"
            for i, content in enumerate(crawled_content[:3], 1):  # Limit to top 3 articles
                current_content_section += f"\n{i}. æ¨™é¡Œï¼š{content.title}\n"
                current_content_section += f"   ä¾†æºï¼š{content.source}\n"
                current_content_section += f"   æ‘˜è¦ï¼š{content.summary}\n"
            current_content_section += "\nè«‹æ ¹æ“šä»¥ä¸Šæœ€æ–°è³‡è¨Šï¼Œçµåˆå®¢å®¶æ–‡åŒ–è¦–è§’é€²è¡Œæ’­å®¢å…§å®¹å‰µä½œã€‚"
        
        prompt = f"""
è«‹ç‚ºä»¥ä¸‹ä¸»é¡Œå‰µå»ºä¸€å€‹ {request.duration} åˆ†é˜çš„å®¢å®¶æ–‡åŒ–æ’­å®¢è…³æœ¬ï¼š"{request.topic}"

è¦æ±‚ï¼š
- ä½¿ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«
- {tone_instructions.get(request.tone, 'ä½¿ç”¨è¦ªåˆ‡ã€å°è©±çš„èªèª¿')}
- å°ˆæ³¨æ–¼å®¢å®¶æ–‡åŒ–ã€å‚³çµ±å’Œéºç”¢
- å…§å®¹è¦å¼•äººå…¥å‹ä¸”çœŸå¯¦
- åŒ…å«æ–‡åŒ–èƒŒæ™¯å’Œæ­·å²è„ˆçµ¡
- çµæ§‹æ¸…æ™°ï¼šé–‹å ´ç™½ã€ä¸»è¦å…§å®¹ã€çµèª
- èªé€Ÿä¼°ç®—ï¼šæ¯åˆ†é˜ç´„ 200-250 å­—
{current_content_section}

{"å€‹äººèˆˆè¶£èå…¥ï¼š" + request.interests if request.interests else ""}

è«‹åœ¨ç¬¬ä¸€è¡Œæä¾›å¸å¼•äººçš„æ¨™é¡Œï¼Œç„¶å¾Œæä¾›å®Œæ•´çš„æ’­å®¢è…³æœ¬ã€‚
å…§å®¹æ‡‰è©²é©åˆå¾ŒçºŒç¿»è­¯ç‚ºå®¢å®¶è©±ä¸¦è£½ä½œæˆèªéŸ³æ’­å®¢ã€‚
"""
        
        return prompt
    
    def _extract_title(self, content: str) -> str:
        """Extract title from the generated content"""
        lines = content.strip().split('\n')
        if lines:
            # First non-empty line is likely the title
            for line in lines:
                if line.strip():
                    return line.strip()
        return "Hakka Podcast"
    
    def _generate_chinese_fallback(self, request: PodcastGenerationRequest) -> Dict[str, Any]:
        """Generate fallback Chinese content when Gemini is not available"""
        
        fallback_content = f"""
{request.topic} - å®¢å®¶æ–‡åŒ–æ¢ç´¢

æ­¡è¿ä¾†åˆ°æˆ‘å€‘çš„å®¢å®¶æ’­å®¢ï¼ä»Šå¤©æˆ‘å€‘è¦æ¢è¨é—œæ–¼{request.topic}é€™å€‹è¿·äººçš„ä¸»é¡Œã€‚

[é€™æ˜¯æ¼”ç¤ºç‰ˆæœ¬ã€‚å¦‚éœ€AIç”Ÿæˆå…§å®¹ï¼Œè«‹åœ¨.envæ–‡ä»¶ä¸­é…ç½®æ‚¨çš„Gemini APIå¯†é‘°ã€‚]

å®¢å®¶æ–‡åŒ–æ“æœ‰è±å¯Œçš„å‚³çµ±å’Œæ­·å²ã€‚æˆ‘å€‘çš„ç¥–å…ˆå¾ä¸­åœ‹åŒ—æ–¹é·å¾™è€Œä¾†ï¼Œå¸¶ä¾†äº†ç¨ç‰¹çš„ç¿’ä¿—ã€èªè¨€å’Œé£²é£Ÿå‚³çµ±ï¼Œé€™äº›éƒ½è¢«ä¸–ä»£ä¿å­˜ä¸‹ä¾†ã€‚

ç„¡è«–æˆ‘å€‘ä»¥{request.tone}çš„æ–¹å¼è¨è«–{request.topic}ï¼Œç¸½æœ‰æ–°çš„ç™¼ç¾ç­‰è‘—æˆ‘å€‘å»æ¢ç´¢å®¢å®¶æ–‡åŒ–éºç”¢ã€‚å¾å‚³çµ±æ­Œè¬ å’Œæ•…äº‹åˆ°å¤è€æ™ºæ…§çš„ç¾ä»£è©®é‡‹ï¼Œå®¢å®¶æ–‡åŒ–åœ¨ä¿æŒæ ¸å¿ƒåƒ¹å€¼çš„åŒæ™‚æŒçºŒç™¼å±•ã€‚

å®¢å®¶è©±æœ¬èº«å°±æ˜¯ä¸€å€‹è¡¨é”å¯¶åº«ï¼Œæ•æ‰äº†æˆ‘å€‘æ°‘æ—å …éŸŒä¸æ‹”å’Œç¤¾å€ç²¾ç¥çš„ç²¾é«“ã€‚é€šéé€™äº›æ’­å®¢ï¼Œæˆ‘å€‘å¸Œæœ›èˆ‡æ¯èªä½¿ç”¨è€…å’Œæ­£åœ¨å­¸ç¿’æ–‡åŒ–éºç”¢çš„äººå€‘åˆ†äº«é€™ç¾éº—çš„æ–‡åŒ–ã€‚

æ„Ÿè¬æ‚¨åŠ å…¥æˆ‘å€‘çš„æ–‡åŒ–ä¹‹æ—…ã€‚ä¸‹æ¬¡è¦‹ï¼Œç¹¼çºŒæ¢ç´¢å’Œæ…¶ç¥æ‚¨çš„å®¢å®¶æ ¹æºï¼

[æ™‚é•·ï¼šç´„{request.duration}åˆ†é˜]
"""
        
        return {
            "title": f"{request.topic} - å®¢å®¶æ–‡åŒ–æ¢ç´¢",
            "content": fallback_content
        }
    
    async def _generate_fallback_content(self, request: PodcastGenerationRequest) -> Dict[str, Any]:
        """Generate complete fallback content when services are not available"""
        
        chinese_content = self._generate_chinese_fallback(request)
        
        # Mock translation
        hakka_content = chinese_content["content"].replace("æ­¡è¿", "æ­¡è¿æ±").replace("æˆ‘å€‘", "ä¿š")
        
        return {
            "title": chinese_content["title"],
            "chinese_content": chinese_content["content"],
            "hakka_content": hakka_content,
            "romanization": "",
            "audio_url": None,
            "audio_duration": 0
        }

    async def generate_podcast_script_with_agents(self, articles, max_minutes=25):
        """Generate podcast script using agent-based conversation (merged from agents.py)"""
        ai_service = PydanticAIService()
        host_a = HostAgent("ä½³æ˜€", "ç†æ€§ã€å°ˆæ¥­ã€åˆ†æ", ai_service)
        host_b = HostAgent("æ•æ¬Š", "å¹½é»˜ã€æ´»æ½‘ã€äº’å‹•", ai_service)
        dialogue = []
        total_chars = 0
        max_chars = max_chars_for_duration(max_minutes)
        per_article_chars = max_chars // len(articles)
        turn = 0

        # é–‹å ´
        dialogue.append("ä½³æ˜€: å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯ä½³æ˜€ã€‚")
        dialogue.append("æ•æ¬Š: æˆ‘æ˜¯æ•æ¬Šï¼Œæ­¡è¿æ”¶è½Hakkast å“ˆå®¢æ’­ã€‚")
        dialogue.append("ä½³æ˜€: ä»Šå¤©æˆ‘å€‘ç‚ºå¤§å®¶å¸¶ä¾†ä¸‰å‰‡é‡è¦æ–°èï¼Œè®“æˆ‘å€‘ä¸€èµ·çœ‹çœ‹ï¼")

        for idx, article in enumerate(articles):
            article_chars = 0

            # ç”¨ LLM ç”¢ç”Ÿç²¾ç°¡æ‘˜è¦
            summary_prompt = (
                "è«‹ä½ ç”¨è‡ªç„¶çš„èªæ°£ï¼Œåƒæœ‹å‹èŠå¤©ä¸€æ¨£ï¼Œé †å‹¢å¸¶å‡ºä¸‹é¢é€™å‰‡æ–°èçš„é‡é»æ‘˜è¦ï¼Œ"
                "ä¸è¦ç”¨ã€é€™å‰‡æ–°èçš„é‡é»æ˜¯ã€ã€ã€æ¥ä¸‹ä¾†ã€ç­‰åˆ¶å¼é–‹é ­ï¼Œ"
                "è€Œæ˜¯ç”¨è©•è«–ã€æ„Ÿæƒ³ã€æˆ–å»¶ä¼¸è©±é¡Œçš„æ–¹å¼è‡ªç„¶éŠœæ¥ï¼Œ50å­—ä»¥å…§ï¼š\n"
                f"{article.content or article.summary}"
            )
            brief = await ai_service.generate_reply(summary_prompt)
            # é™åˆ¶æ‘˜è¦æœ€å¤šå››å¥
            sentences = brief.strip().split("ã€‚")
            intro = f"ä½³æ˜€: {'ã€‚'.join(sentences[:5]).strip()}"
            dialogue.append(intro)

            for round in range(30):
                is_last_turn = (article_chars + 100 > per_article_chars * 0.95)
                if article_chars > per_article_chars * 0.95 or total_chars > max_chars * 0.95:
                    break  
                if turn % 2 == 0:
                    reply = await host_a.reply(dialogue, articles, idx, turn, is_last_turn)
                else:
                    reply = await host_b.reply(dialogue, articles, idx, turn, is_last_turn)
                dialogue.append(reply)
                total_chars += len(reply)
                article_chars += len(reply)
                turn += 1

        # ä¸‰ç¯‡æ–°èè¨è«–å®Œï¼Œé€²å…¥æ”¶å°¾
        news_list = "\n".join([f"{i+1}. {(a.summary or a.content)[:60]}" for i, a in enumerate(articles)])

        summary_prompt_a = (
            f"è«‹ä½ ä»¥ä½³æ˜€çš„èº«åˆ†ï¼Œé‡å°ä»Šå¤©è¨è«–çš„ä¸‰å‰‡æ–°èåšä¸€å€‹é‡é»ç¸½çµã€‚\n"
            f"æœ¬é›†ä¸‰å‰‡æ–°èåˆ†åˆ¥æ˜¯ï¼š\n{news_list}\n"
            "è«‹ç›´æ¥ç”¨è‡ªç„¶èªè¨€ç¸½çµä»Šå¤©çš„è¨è«–å…§å®¹ï¼Œå‹™å¿…ä¸å¯å‡ºç¾ä»»ä½•[æ–°èä¸€ä¸»é¡Œ]ã€[çœç•¥]æˆ–ä»»ä½•ä½”ä½ç¬¦ï¼Œ"
            "å…§å®¹è¦å®Œæ•´ã€ç²¾ç°¡ä¸”è²¼åˆæœ¬é›†ä¸»é¡Œï¼Œç´„3~4å¥è©±ï¼Œæ¯å¥è©±ç”¨å¥è™Ÿåˆ†éš”ï¼Œé–‹é ­åŠ ã€Œä½³èŠ¸: ã€"
        )
        summary_a = await ai_service.generate_reply(summary_prompt_a)
        dialogue.append(summary_a.strip())

        summary_prompt_b = (
            "è«‹ä½ ä»¥æ•æ¬Šçš„èº«åˆ†ï¼Œé‡å°ä½³æ˜€çš„ç¸½çµå…§å®¹åšè£œå……æˆ–åˆ†äº«å€‹äººè§€é»ï¼Œ"
            "èªæ°£è¼•é¬†ï¼Œç´„2~3å¥è©±ï¼Œæ¯å¥è©±ç”¨å¥è™Ÿåˆ†éš”ï¼Œé–‹é ­åŠ ã€Œæ•æ¬Š: ã€"
        )
        summary_b = await ai_service.generate_reply(summary_prompt_b)
        dialogue.append(summary_b.strip())

        ending_prompt_a = (
            "è«‹ä½ ä»¥ä½³æ˜€çš„èº«åˆ†ï¼Œç”¨ä¸€æ®µè©±åšæœ¬é›†æ’­å®¢çš„æº«é¦¨çµèªï¼Œ"
            "å…§å®¹è¦å‘¼æ‡‰ä»Šå¤©è¨è«–çš„ä¸‰å‰‡æ–°èï¼Œé–‹é ­åŠ ã€Œä½³æ˜€: ã€ï¼Œä¸è¦æœ‰ä»»ä½•ä½”ä½ç¬¦ã€‚"
        )
        ending_a = await ai_service.generate_reply(ending_prompt_a)
        dialogue.append(ending_a.strip())

        def merge_same_speaker_lines(dialogue_lines):
            merged = []
            buffer = ""
            last_speaker = None
            for line in dialogue_lines:
                line = line.strip()
                if not line:
                    continue
                if line.startswith("ä½³æ˜€:"):
                    speaker = "ä½³æ˜€"
                elif line.startswith("æ•æ¬Š:"):
                    speaker = "æ•æ¬Š"
                else:
                    speaker = None

                if speaker and speaker == last_speaker:
                    buffer += " " + line[len(speaker)+1:].strip()
                else:
                    if buffer:
                        merged.append(buffer)
                    buffer = line
                    last_speaker = speaker
            if buffer:
                merged.append(buffer)
            return merged

        # åˆä½µåŒä¸»æŒäººç™¼è¨€ï¼Œä¸¦åœ¨ä¸åŒä¸»æŒäººæ™‚æ›è¡Œ
        merged_lines = merge_same_speaker_lines(dialogue)
        # è½‰æˆçµæ§‹åŒ–é™£åˆ—
        content = []
        for line in merged_lines:
            if line.startswith("ä½³æ˜€:"):
                content.append(PodcastScriptContent(speaker="ä½³æ˜€", text=line[len("ä½³æ˜€:"):].strip()))
            elif line.startswith("æ•æ¬Š:"):
                content.append(PodcastScriptContent(speaker="æ•æ¬Š", text=line[len("æ•æ¬Š:"):].strip()))
        podcast_script = PodcastScript(
            title="Hakkast å“ˆå®¢æ’­æ–°èè¨è«–",
            hosts=["ä½³æ˜€", "æ•æ¬Š"],
            content=content
        )
        print(f"è…³æœ¬å­—æ•¸ï¼š{sum(len(c.text) for c in content)}")
        return podcast_script


# å¾ agents.py åˆä½µéä¾†çš„ä¸»è¦å‡½æ•¸ï¼Œä¾›å¤–éƒ¨èª¿ç”¨
async def generate_podcast_script_with_agents(articles, max_minutes=25):
    """
    Generate podcast script with agents - main function from agents.py
    This is the primary function for agent-based podcast script generation
    """
    ai_service_instance = AIService()
    return await ai_service_instance.generate_podcast_script_with_agents(articles, max_minutes)
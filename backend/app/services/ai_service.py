import os
import google.generativeai as genai
from typing import Dict, Any, List, Optional
from pydantic import BaseModel
from pydantic_ai import Agent
from pydantic_ai.models.gemini import GeminiModel
from pydantic_ai.models.openai import OpenAIModel
import asyncio
from datetime import datetime
from app.core.config import settings
from app.models.podcast import PodcastGenerationRequest, PodcastScript, PodcastScriptContent
from app.services.translation_service import TranslationService
from app.services.tts_service import TTSService
from app.services.crawl4ai_service import crawl_news
from app.models.crawler import CrawledContent

# çµæ§‹åŒ–çš„å›æ‡‰æ¨¡å‹ (å¾ pydantic_ai_service.py åˆä½µ)
class PydanticPodcastScript(BaseModel):
    title: str
    hosts: List[str]  
    full_dialogue: str  
    estimated_duration_minutes: int
    key_points: List[str]
    sources_mentioned: List[str]


class ContentAnalysis(BaseModel):
    """å…§å®¹åˆ†æçµæœæ¨¡å‹"""
    topic_category: str
    complexity_level: str  # "beginner", "intermediate", "advanced"
    target_audience: str
    recommended_style: str
    content_freshness: str  # "current", "evergreen", "historical"


class PydanticAIService:
    """ä½¿ç”¨ Pydantic AI ( TWCC AFS å’Œ Gemini ) - å¾ pydantic_ai_service.py åˆä½µ"""
 
    def __init__(self, use_twcc: bool = True):
        self.use_twcc = use_twcc
        
        if use_twcc and settings.TWCC_API_KEY and settings.TWCC_BASE_URL:
            # TWCC AFS 
            print("ä½¿ç”¨ TWCC AFS ...")
            os.environ["OPENAI_API_KEY"] = settings.TWCC_API_KEY
            os.environ["OPENAI_BASE_URL"] = settings.TWCC_BASE_URL
            self.model = OpenAIModel(settings.TWCC_MODEL_NAME)
        elif settings.GEMINI_API_KEY:
            # Gemini 
            print("ä½¿ç”¨ Gemini æ¨¡å‹...")
            os.environ["GEMINI_API_KEY"] = settings.GEMINI_API_KEY
            self.model = GeminiModel('gemini-2.5-flash')
            self.use_twcc = False
        else:
            raise ValueError("éœ€è¦è¨­å®š TWCC_API_KEY + TWCC_BASE_URL æˆ– GEMINI_API_KEY")
        
        # å‰µå»ºå…§å®¹åˆ†æ Agent
        self.content_analyzer = Agent(
            model=self.model,
            result_type=ContentAnalysis,
            system_prompt="""
            ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å…§å®¹åˆ†æå¸«ï¼Œå°ˆé–€åˆ†ææ’­å®¢ä¸»é¡Œå’Œå—çœ¾éœ€æ±‚ã€‚
            åˆ†æç”¨æˆ¶æä¾›çš„ä¸»é¡Œï¼Œåˆ¤æ–·ï¼š
            1. ä¸»é¡Œé¡åˆ¥ï¼ˆç§‘æŠ€ã€å¨›æ¨‚ã€æ•™è‚²ã€æ–°èç­‰ï¼‰
            2. è¤‡é›œåº¦ç­‰ç´šï¼ˆåˆå­¸è€…ã€ä¸­ç´šã€é«˜ç´šï¼‰
            3. ç›®æ¨™å—çœ¾
            4. æ¨è–¦çš„æ’­å®¢é¢¨æ ¼
            5. å…§å®¹æ™‚æ•ˆæ€§
            
            è«‹ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰ï¼Œä¸¦æä¾›å°ˆæ¥­çš„åˆ†æçµæœã€‚
            """
        )
        
        # å‰µå»ºè…³æœ¬ç”Ÿæˆ Agent
        self.script_generator = Agent(
            model=self.model,
            result_type=PydanticPodcastScript,
            system_prompt="""
            ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ’­å®¢è…³æœ¬å‰µä½œè€…ï¼Œå°ˆé–€å‰µä½œé›™ä¸»æŒäººæ·±åº¦å°è©±å½¢å¼çš„æ–°èåˆ†ææ’­å®¢ã€‚

            è…³æœ¬æ ¼å¼è¦æ±‚ï¼š
            1. æ¨™é¡Œï¼šæº–ç¢ºä¸”å¸å¼•äººï¼Œåæ˜ æ–°èæ ¸å¿ƒè­°é¡Œ
            2. é›™ä¸»æŒäººï¼šä¸»æŒäººAå’Œä¸»æŒäººBé€²è¡Œæ·±å…¥å°è©±åˆ†æ
            3. å®Œæ•´å°è©±è…³æœ¬ç‰¹è‰²ï¼š
               - é–‹å ´ï¼šä»‹ç´¹ç¯€ç›®å’Œç•¶å¤©ä¸»é¡Œ
               - æ–°èèƒŒæ™¯ï¼šè©³ç´°ä»‹ç´¹æ–°èäº‹ä»¶
               - æ·±åº¦åˆ†æï¼šå¾å¤šè§’åº¦åˆ†æäº‹ä»¶æ„ç¾©å’Œå½±éŸ¿
               - åœ°ç·£æ”¿æ²»ï¼šåˆ†æèƒŒå¾Œçš„åœ‹éš›é—œä¿‚å’Œæˆ°ç•¥è€ƒé‡
               - ç¶“æ¿Ÿå±¤é¢ï¼šè¨è«–è²¿æ˜“ã€ç¶“æ¿Ÿåˆä½œç­‰è­°é¡Œ
               - ç¸½çµï¼šæ­¸ç´é‡é»å’Œå¾ŒçºŒç™¼å±•é æ¸¬
               - çµå°¾ï¼šæ„Ÿè¬æ”¶è½å’Œé å‘Š
            4. å°è©±é¢¨æ ¼ï¼š
               - å°ˆæ¥­æ·±å…¥ä½†é€šä¿—æ˜“æ‡‚
               - ä¸€å•ä¸€ç­”ï¼Œäº’ç›¸è£œå……å’Œæ·±å…¥
               - æ¯æ®µå°è©±éƒ½æœ‰å¯¦è³ªå…§å®¹ï¼Œé¿å…ç©ºæ´
               - åŒ…å«å…·é«”çš„æ•¸æ“šã€äº‹å¯¦å’ŒèƒŒæ™¯è³‡è¨Š
               - æ¯æ®µå°è©±å‰æ¨™è¨»èªªè©±è€…ï¼ˆğŸ™ï¸ä¸»æŒäººA: / ğŸ™ï¸ä¸»æŒäººB:ï¼‰
            5. å…§å®¹æ·±åº¦è¦æ±‚ï¼š
               - åˆ†ææ–°èèƒŒå¾Œçš„æ·±å±¤åŸå› 
               - è¨è«–åœ°ç·£æ”¿æ²»å’Œæˆ°ç•¥æ„ç¾©
               - è§£é‡‹è¤‡é›œçš„åœ‹éš›é—œä¿‚
               - æä¾›å¤šè§’åº¦çš„è§€é»
               - é æ¸¬å¯èƒ½çš„å¾ŒçºŒç™¼å±•
            6. é•·åº¦è¦æ±‚ï¼šç”Ÿæˆè¶³å¤ é•·çš„å°è©±å…§å®¹ï¼Œç¢ºå¯¦ç¬¦åˆç›®æ¨™æ™‚é•·ï¼ˆä¾‹å¦‚ä¸‰ç¯‡æ–°èå…±15åˆ†é˜ï¼Œæ¯ç¯‡ç´„5åˆ†é˜ï¼‰
            7. ä¸²æ¥è¦æ±‚ï¼šä¸‰ç¯‡æ–°èè«‹ä»¥è‡ªç„¶çš„å°è©±æ–¹å¼ä¸²æ¥ï¼Œä¸»æŒäººèƒ½é †æš¢åœ°å¾ä¸€å‰‡æ–°èå¸¶åˆ°ä¸‹ä¸€å‰‡æ–°èï¼Œè®“è½çœ¾æ„Ÿè¦ºä¸»é¡Œé€£è²«ã€‚
            åƒè€ƒå„ªè³ªå°è©±é¢¨æ ¼ï¼š
            - ä¸åªé™³è¿°äº‹å¯¦ï¼Œé‚„è¦åˆ†æåŸå› å’Œå½±éŸ¿
            - ç”¨"æ²’éŒ¯ï¼Œè€Œä¸”..."ã€"å°ï¼Œä½†æœ‰è¶£çš„æ˜¯..."ç­‰éæ¸¡èª
            - åŒ…å«"å¾æ–°èä¾†çœ‹..."ã€"é€™èƒŒå¾Œå¯ä¸å–®ç´”..."ç­‰åˆ†ææ€§èªå¥
            - ç¸½çµæ™‚ç”¨"æˆ‘å€‘ç¸½çµä¸€ä¸‹ä»Šå¤©çš„é‡é»..."
            è«‹ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«ï¼Œé¢¨æ ¼å°ˆæ¥­ä¸”æœ‰æ·±åº¦ã€‚
            """
        )
        
        # æ–°å¢æ‘˜è¦ agent
        self.summarizer = Agent(
            model=self.model,
            result_type=str,
            system_prompt="""
            ä½ æ˜¯ä¸€ä½å°ˆæ¥­æ–°èæ‘˜è¦å“¡ï¼Œåªç”¢ç”Ÿç´”æ–‡å­—æ‘˜è¦ï¼Œä¸è¦ä¸»æŒäººã€å°è©±æˆ–è™›æ§‹å…§å®¹ã€‚
            è«‹ç”¨ç¹é«”ä¸­æ–‡ï¼Œæ¿ƒç¸®æ–°èé‡é»ï¼Œå­—æ•¸ç´„500å­—ã€‚
            """
        )
        
        # å‰µå»ºå°è©± Agent
        self.dialogue_agent = Agent(
            model=self.model,
            result_type=str,
            system_prompt="""
            ä½ æ˜¯å°ˆæ¥­æ’­å®¢ä¸»æŒäººï¼Œè«‹æ ¹æ“šä¸Šä¸‹æ–‡å’Œæ–°èæ‘˜è¦ï¼Œç”¢ç”Ÿä¸€æ®µè‡ªç„¶ã€æ·±å…¥çš„å°è©±å›æ‡‰ã€‚
            è«‹ç”¨ç¹é«”ä¸­æ–‡ï¼Œé¢¨æ ¼å°ˆæ¥­ä¸”æœ‰æ·±åº¦ã€‚
            """
        )
        
        # å‰µå»ºè‹±æ–‡è½‰ç¾…é¦¬æ‹¼éŸ³ Agent
        self.english_romanizer = Agent(
            model=self.model,
            result_type=str,
            system_prompt="""
            ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„èªéŸ³è½‰æ›å°ˆå®¶ï¼Œå°ˆé–€è™•ç†æ··åˆä¸­è‹±æ–‡æ–‡æœ¬ä¸­çš„è‹±æ–‡å–®å­—è½‰æ›ã€‚

            ä»»å‹™ï¼šå°‡æ–‡æœ¬ä¸­çš„è‹±æ–‡å–®å­—è½‰æ›æˆå¸¶æ•¸å­—æ¨™èª¿çš„ç¾…é¦¬æ‹¼éŸ³æ ¼å¼ï¼Œä»¥ä¾¿å®¢å®¶è©±TTSç³»çµ±æ­£ç¢ºç™¼éŸ³ã€‚

            è½‰æ›è¦å‰‡ï¼š
            1. è‹±æ–‡å–®å­—è½‰æ›æˆè¿‘ä¼¼çš„ç¾…é¦¬æ‹¼éŸ³ç™¼éŸ³
            2. ä¿æŒä¸­æ–‡éƒ¨åˆ†å®Œå…¨ä¸è®Š
            3. æ¯å€‹éŸ³ç¯€å¿…é ˆæ·»åŠ æ•¸å­—æ¨™èª¿ï¼ˆ24è¡¨ç¤ºä¸­å¹³èª¿ï¼Œ55è¡¨ç¤ºé«˜å¹³èª¿ï¼Œ11è¡¨ç¤ºä½å¹³èª¿ï¼Œ2è¡¨ç¤ºä¸Šè²ï¼Œ31è¡¨ç¤ºå»è²ï¼‰
            4. ä½¿ç”¨ç©ºæ ¼åˆ†éš”æ¯å€‹éŸ³ç¯€
            5. å¸¸è¦‹è‹±æ–‡å–®å­—ä½¿ç”¨æ¨™æº–åŒ–éŸ³è­¯

            ç¯„ä¾‹è½‰æ›ï¼š
            - Apple â†’ a24 pu24 er24
            - Google â†’ gu24 ge24 er24
            - Facebook â†’ fei24 si24 bu24 ke24
            - Microsoft â†’ mai24 ke24 ro24 so24 fu24 te24
            - iPhone â†’ ai24 feng24
            - ChatGPT â†’ cha24 te24 ji24 pi24 ti24
            - YouTube â†’ you24 tu24 be24
            - Instagram â†’ yin24 si24 ta24 ge24 lan24 mu24
            - Android â†’ an24 zhuo24 yi24 de24
            - OpenAI â†’ o24 pen24 ai24

            éŸ³èª¿é¸æ“‡å»ºè­°ï¼š
            - ä¸€èˆ¬æƒ…æ³ä½¿ç”¨24ï¼ˆä¸­å¹³èª¿ï¼‰
            - é‡è¦å“ç‰Œåç¨±çš„é‡éŸ³éŸ³ç¯€å¯ä½¿ç”¨55ï¼ˆé«˜å¹³èª¿ï¼‰
            - çµå°¾éŸ³ç¯€å¯ä½¿ç”¨11ï¼ˆä½å¹³èª¿ï¼‰

            è«‹ç›´æ¥è¼¸å‡ºè½‰æ›å¾Œçš„å®Œæ•´æ–‡æœ¬ï¼Œä¿æŒåŸæœ‰çš„å¥å­çµæ§‹å’Œæ¨™é»ç¬¦è™Ÿã€‚
            """
        )

    async def analyze_content_requirements(self, topic: str, tone: str = "casual") -> ContentAnalysis:
        """åˆ†æå…§å®¹éœ€æ±‚å’Œå—çœ¾"""
        try:
            result = await self.content_analyzer.run(
                f"è«‹åˆ†æé€™å€‹æ’­å®¢ä¸»é¡Œï¼š'{topic}'ï¼Œæ’­å®¢é¢¨æ ¼åå‘ï¼š{tone}"
            )
            return result.data
        except Exception as e:
            print(f"Content analysis error: {e}")
            return ContentAnalysis(
                topic_category="é€šç”¨",
                complexity_level="intermediate",
                target_audience="ä¸€èˆ¬è½çœ¾",
                recommended_style="å°è©±å¼",
                content_freshness="evergreen"
            )

    async def generate_podcast_script(
        self, 
        request: PodcastGenerationRequest,
        crawled_content: Optional[List[CrawledContent]] = None,
        content_analysis: Optional[ContentAnalysis] = None
    ) -> PydanticPodcastScript:
        """ç”Ÿæˆçµæ§‹åŒ–çš„æ’­å®¢è…³æœ¬"""
        
        # å¦‚æœæ²’æœ‰å…§å®¹åˆ†æï¼Œå…ˆé€²è¡Œåˆ†æ
        if not content_analysis:
            content_analysis = await self.analyze_content_requirements(
                request.topic, 
                request.tone or "casual"
            )
        
        # æº–å‚™ä¸Šä¸‹æ–‡è³‡è¨Š
        context_info = f"""
        ä¸»é¡Œï¼š{request.topic}
        é¢¨æ ¼ï¼š{request.tone or 'casual'}
        ç›®æ¨™æ™‚é•·ï¼š{request.duration or 10} åˆ†é˜
        
        å…§å®¹åˆ†æçµæœï¼š
        - é¡åˆ¥ï¼š{content_analysis.topic_category}
        - è¤‡é›œåº¦ï¼š{content_analysis.complexity_level}
        - ç›®æ¨™å—çœ¾ï¼š{content_analysis.target_audience}
        - æ¨è–¦é¢¨æ ¼ï¼š{content_analysis.recommended_style}
        - å…§å®¹æ™‚æ•ˆæ€§ï¼š{content_analysis.content_freshness}
        """
        
        # åŠ å…¥åƒè€ƒè³‡æ–™
        if crawled_content:
            context_info += "\n\nåƒè€ƒè³‡æ–™ï¼š\n"
            for content in crawled_content[:3]:  
                context_info += (
                    f"- æ¨™é¡Œï¼š{content.title}\n"
                    f"  å…§å®¹ï¼š{(content.content or content.summary)[:1500]}...\n"
                )
                
        try:
            result = await self.script_generator.run(context_info)
            return result.data
        except Exception as e:
            print(f"Script generation error: {e}")
            return self._create_fallback_script(request)

    async def generate_complete_podcast_content(
        self, 
        request: PodcastGenerationRequest,
        crawled_content: Optional[List[CrawledContent]] = None
    ) -> Dict[str, Any]:
        """å®Œæ•´çš„æ’­å®¢å…§å®¹ç”Ÿæˆæµç¨‹"""
        try:
            print("æ­£åœ¨åˆ†æå…§å®¹éœ€æ±‚...")
            content_analysis = await self.analyze_content_requirements(request.topic, request.tone)

            # é€ç¯‡æ‘˜è¦
            summaries = []
            if crawled_content:
                for content in crawled_content[:3]:
                    summary = await self.summarize_article(content.content or content.summary)
                    summaries.append(f"æ¨™é¡Œï¼š{content.title}\næ‘˜è¦ï¼š{summary}\nä¾†æºï¼š{content.url}")

            # Step 2: åˆä½µæ‘˜è¦ä¸¦ç”±LLMç”¢ç”Ÿè…³æœ¬
            combined_summary = "\n\n".join(summaries)
            podcast_prompt = (
                "è«‹æ ¹æ“šä»¥ä¸‹ä¸‰ç¯‡æ–°èçš„é‡é»æ‘˜è¦ï¼Œé€ä¸€åˆ†æä¸¦ä¸²æ¥ï¼Œ"
                "ç”Ÿæˆä¸€ä»½ç´„2200~2500å­—ã€15åˆ†é˜çš„é›™ä¸»æŒäººæ’­å®¢è…³æœ¬ã€‚"
                "å…§å®¹å¿…é ˆæ¶µè“‹ä¸‰ç¯‡æ–°èçš„é‡é»ï¼Œä¸”ä¸è¦è™›æ§‹ï¼š\n"
                f"{combined_summary}"
            )
            # ç”¨è…³æœ¬ç”Ÿæˆ agent ç”¢ç”Ÿè…³æœ¬
            script = await self.script_generator.run(podcast_prompt)

            # åˆ†æ®µç”Ÿæˆ
            segments = []

            # é–‹å ´
            opening_prompt = (
                "è«‹æ ¹æ“šä»¥ä¸‹ä¸‰ç¯‡æ–°èæ‘˜è¦ï¼Œç”Ÿæˆæ’­å®¢é–‹å ´ç™½ï¼ˆç´„700å­—ï¼‰ï¼Œ"
                "ä»‹ç´¹ä¸»é¡Œä¸¦å¸å¼•è½çœ¾ï¼š\n"
                f"{combined_summary}"
            )
            opening = await self.generate_podcast_script_segment(opening_prompt)
            segments.append(opening)

            # ä¸‰ç¯‡æ–°èåˆ†åˆ¥ç”Ÿæˆ
            for idx, summary in enumerate(summaries, 1):
                news_prompt = (
                    f"è«‹æ ¹æ“šä»¥ä¸‹æ–°èæ‘˜è¦ï¼Œç”Ÿæˆæ’­å®¢å°è©±æ®µè½ï¼ˆç´„800å­—ï¼‰ï¼Œ"
                    f"ä¸»é¡Œï¼šç¬¬{idx}ç¯‡æ–°è\n{summary}"
                )
                news_segment = await self.generate_podcast_script_segment(news_prompt)
                segments.append(news_segment)

            # çµå°¾
            closing_prompt = (
                "è«‹æ ¹æ“šä»¥ä¸Šå…§å®¹ï¼Œç”Ÿæˆæ’­å®¢çµå°¾ç¸½çµï¼ˆç´„400å­—ï¼‰ï¼Œ"
                "æ­¸ç´é‡é»ä¸¦é å‘Šä¸‹é›†ã€‚"
            )
            closing = await self.generate_podcast_script_segment(closing_prompt)
            segments.append(closing)

            # åˆä½µæ®µè½
            full_script = "\n\n".join(segments)
            
            # æš«æ™‚è·³éè‹±æ–‡è™•ç†ï¼Œå°‡åœ¨ç¿»è­¯éšæ®µè™•ç†ç¾…é¦¬æ‹¼éŸ³ä¸­çš„è‹±æ–‡
            print("è·³éè‹±æ–‡è™•ç†ï¼Œå°‡åœ¨ç¿»è­¯éšæ®µè™•ç†...")
            tts_ready_script = full_script

            # å®Œæ•´å…§å®¹ï¼ˆå°è©±è…³æœ¬ï¼‰
            full_content = f"""
            Podcast æ¨™é¡Œï¼š{script.title}

            ä¸»æŒäººï¼š{' èˆ‡ '.join(script.hosts)}

            {script.full_dialogue}
            """

            return {
                "success": True,
                "model_info": {"model_type": "TWCC AFS" if self.use_twcc else "Gemini"},
                "content_analysis": content_analysis.dict(),
                "structured_script": {
                    "title": script.title if 'script' in locals() else request.topic,
                    "hosts": ["ä¸»æŒäººA", "ä¸»æŒäººB"],
                    "full_dialogue": full_script,
                    "estimated_duration_minutes": request.duration,
                    "key_points": [],
                    "sources_mentioned": []
                },
                "full_content": full_script,
                "tts_ready_content": tts_ready_script,  # æ–°å¢ï¼šå°ˆç‚ºTTSæº–å‚™çš„å…§å®¹
                "generation_timestamp": datetime.now().isoformat(),
                "processing_steps": [
                    "å…§å®¹éœ€æ±‚åˆ†æ",
                    "é€ç¯‡æ‘˜è¦",
                    "åˆ†æ®µç”Ÿæˆ",
                    "è‹±æ–‡è½‰æ›è™•ç†",
                    "å…§å®¹æ•´åˆå®Œæˆ"
                ]
            }

        except Exception as e:
            print(f"Complete generation error: {e}")
            return {
                "success": False,
                "error": str(e),
                "fallback_content": self._create_fallback_script(request).dict()
            }

    def _create_fallback_script(self, request: PodcastGenerationRequest) -> PydanticPodcastScript:
        """å‰µå»ºå‚™ç”¨è…³æœ¬"""
        fallback_dialogue = f"""
        ä¸»æŒäººAï¼š
        æ­¡è¿æ”¶è½ä»Šå¤©çš„æ’­å®¢ç¯€ç›®ï¼Œæˆ‘æ˜¯ä¸»æŒäººAã€‚

        ä¸»æŒäººBï¼š
        æˆ‘æ˜¯ä¸»æŒäººBã€‚ä»Šå¤©æˆ‘å€‘è¦èŠçš„ä¸»é¡Œæ˜¯{request.topic}ã€‚

        ä¸»æŒäººAï¼š
        é€™ç¢ºå¯¦æ˜¯ä¸€å€‹å¾ˆæœ‰è¶£çš„è©±é¡Œï¼Œè®“æˆ‘å€‘ä¾†æ·±å…¥è¨è«–ä¸€ä¸‹ã€‚

        ä¸»æŒäººBï¼š
        æ²’éŒ¯ï¼Œé€™å€‹è­°é¡Œå€¼å¾—æˆ‘å€‘å¾å¤šå€‹è§’åº¦ä¾†åˆ†æã€‚

        ä¸»æŒäººAï¼š
        æ„Ÿè¬å¤§å®¶ä»Šå¤©çš„æ”¶è½ï¼Œæˆ‘å€‘ä¸‹æ¬¡å†è¦‹ï¼
        """
        
        return PydanticPodcastScript(
            title=f"é—œæ–¼{request.topic}çš„è¨è«–",
            hosts=["ä¸»æŒäººA", "ä¸»æŒäººB"],
            full_dialogue=fallback_dialogue,
            estimated_duration_minutes=request.duration or 10,
            key_points=[f"{request.topic}ç›¸é—œè¦é»"],
            sources_mentioned=["ä¸€èˆ¬çŸ¥è­˜"]
        )

    async def summarize_article(self, article_content: str) -> str:
        """ç”¨ LLM ç”¢ç”Ÿå–®ç¯‡æ–°èæ‘˜è¦ï¼Œé¿å…å¹»è¦º"""
        prompt = f"è«‹ç”¨550ä»¥å…§å­—æ‘˜è¦ä»¥ä¸‹æ–°èå…§å®¹ï¼Œåªç”¨çœŸå¯¦æ–°èç´°ç¯€ï¼Œä¸è¦è™›æ§‹ï¼š\n{article_content}"
        result = await self.summarizer.run(prompt)
        return str(result.data)

    async def generate_podcast_script_segment(self, segment_prompt: str) -> str:
        """åˆ†æ®µç”Ÿæˆæ’­å®¢è…³æœ¬ç‰‡æ®µ"""
        result = await self.script_generator.run(segment_prompt)
        return str(result.data.full_dialogue) if hasattr(result.data, "full_dialogue") else str(result.data)

    async def generate_reply(self, prompt: str, output_type=None) -> str:
        """ç”Ÿæˆå°è©±å›æ‡‰"""
        if output_type:
            agent = Agent(model=self.model, output_type=output_type)
            result = await agent.run(prompt)
            return result.output
        else:
            # default:dialogue_agent
            result = await self.dialogue_agent.run(prompt)
            return result.data

    async def convert_english_to_romanization(self, text: str) -> str:
        """å°‡æ–‡æœ¬ä¸­çš„è‹±æ–‡å–®å­—è½‰æ›æˆå¸¶æ•¸å­—æ¨™èª¿çš„ç¾…é¦¬æ‹¼éŸ³æ ¼å¼"""
        try:
            prompt = f"""
            è«‹å°‡ä»¥ä¸‹æ–‡æœ¬ä¸­çš„è‹±æ–‡å–®å­—è½‰æ›æˆå¸¶æ•¸å­—æ¨™èª¿çš„ç¾…é¦¬æ‹¼éŸ³æ ¼å¼ï¼Œä¸­æ–‡éƒ¨åˆ†ä¿æŒä¸è®Šï¼š

            åŸæ–‡ï¼š
            {text}

            è½‰æ›è¦æ±‚ï¼š
            1. åªè½‰æ›è‹±æ–‡å–®å­—ï¼Œä¸­æ–‡å®Œå…¨ä¸è®Š
            2. è‹±æ–‡è½‰æ›æˆé¡ä¼¼ç™¼éŸ³çš„ç¾…é¦¬æ‹¼éŸ³ï¼Œæ¯å€‹éŸ³ç¯€åŠ æ•¸å­—æ¨™èª¿
            3. æ¨™èª¿è¦å‰‡ï¼š24=ä¸­å¹³èª¿ï¼Œ55=é«˜å¹³èª¿ï¼Œ11=ä½å¹³èª¿ï¼Œ2=ä¸Šè²ï¼Œ31=å»è²
            4. éŸ³ç¯€é–“ç”¨ç©ºæ ¼åˆ†éš”
            5. ä¿æŒåŸæœ‰æ¨™é»ç¬¦è™Ÿå’Œæ ¼å¼
            6. å¸¸è¦‹å“ç‰Œä½¿ç”¨æ¨™æº–éŸ³è­¯ï¼š
               - Apple â†’ a24 pu24 er24
               - Google â†’ gu24 ge24 er24
               - Facebook â†’ fei24 si24 bu24 ke24
               - Microsoft â†’ mai24 ke24 ro24 so24 fu24 te24
               - iPhone â†’ ai24 feng24
               - ChatGPT â†’ cha24 te24 ji24 pi24 ti24

            è«‹ç›´æ¥è¼¸å‡ºè½‰æ›å¾Œçš„å®Œæ•´æ–‡æœ¬ï¼š
            """
            
            result = await self.english_romanizer.run(prompt)
            return result.data
        except Exception as e:
            print(f"English romanization error: {e}")
            # å¦‚æœè½‰æ›å¤±æ•—ï¼Œè¿”å›åŸæ–‡
            return text

    async def process_romanization_for_tts(self, romanization_text: str) -> str:
        """å°ˆé–€è™•ç†romanizationæ¬„ä½ä¸­çš„è‹±æ–‡å–®å­—ï¼Œç‚ºTTSç³»çµ±æº–å‚™çµ±ä¸€æ ¼å¼"""
        try:
            # æª¢æŸ¥æ˜¯å¦åŒ…å«æ²’æœ‰æ•¸å­—æ¨™èª¿çš„è‹±æ–‡å–®å­—
            import re
            
            # å°‹æ‰¾è‹±æ–‡å–®å­—ï¼ˆå­—æ¯çµ„æˆä½†æ²’æœ‰æ•¸å­—æ¨™èª¿ï¼‰
            english_words = re.findall(r'\b[a-zA-Z]+\b', romanization_text)
            
            if not english_words:
                print("æœªæª¢æ¸¬åˆ°éœ€è¦è™•ç†çš„è‹±æ–‡å–®å­—")
                return romanization_text
            
            print(f"æª¢æ¸¬åˆ°è‹±æ–‡å–®å­—: {english_words}")
            
            # ç‚ºæ¯å€‹è‹±æ–‡å–®å­—æ·»åŠ æ¨™èª¿
            processed_text = romanization_text
            
            for word in english_words:
                # è½‰æ›è‹±æ–‡å–®å­—ç‚ºå¸¶æ¨™èª¿çš„ç¾…é¦¬æ‹¼éŸ³
                converted_word = await self.convert_english_word_to_toned_romanization(word)
                
                # æ›¿æ›åŸæ–‡ä¸­çš„è‹±æ–‡å–®å­—
                processed_text = re.sub(r'\b' + re.escape(word) + r'\b', converted_word, processed_text)
                print(f"è½‰æ›: {word} â†’ {converted_word}")
            
            return processed_text
            
        except Exception as e:
            print(f"Romanization processing error: {e}")
            return romanization_text

    async def convert_english_word_to_toned_romanization(self, english_word: str) -> str:
        """å°‡å–®å€‹è‹±æ–‡å–®å­—è½‰æ›ç‚ºå¸¶æ•¸å­—æ¨™èª¿çš„ç¾…é¦¬æ‹¼éŸ³"""
        try:
            import re
            
            prompt = f"""
            è«‹å°‡è‹±æ–‡å–®å­— "{english_word}" è½‰æ›æˆå¸¶æ•¸å­—æ¨™èª¿çš„ç¾…é¦¬æ‹¼éŸ³æ ¼å¼ï¼Œç”¨æ–¼å®¢å®¶è©±TTSç³»çµ±ã€‚

            è½‰æ›è¦å‰‡ï¼š
            1. å°‡è‹±æ–‡å–®å­—åˆ†è§£æˆéŸ³ç¯€
            2. æ¯å€‹éŸ³ç¯€æ·»åŠ æ•¸å­—æ¨™èª¿ï¼ˆä¸»è¦ä½¿ç”¨24=ä¸­å¹³èª¿ï¼‰
            3. éŸ³ç¯€é–“ç”¨ç©ºæ ¼åˆ†éš”
            4. ä¸è¦åŒ…å«åŸè‹±æ–‡å–®å­—ï¼Œåªè¼¸å‡ºç¾…é¦¬æ‹¼éŸ³

            å¸¸è¦‹è½‰æ›ç¯„ä¾‹ï¼š
            - Apple â†’ a24 pu24 er24
            - Google â†’ gu24 ge24 er24
            - Facebook â†’ fei24 si24 bu24 ke24
            - iPhone â†’ ai24 feng24
            - Hakkast â†’ ha24 ka24 si24 te24
            - ChatGPT â†’ cha24 te24 ji24 pi24 ti24

            è«‹åªè¼¸å‡ºè½‰æ›å¾Œçš„ç¾…é¦¬æ‹¼éŸ³ï¼ˆåŒ…å«æ•¸å­—æ¨™èª¿ï¼‰ï¼š
            """
            
            result = await self.english_romanizer.run(prompt)
            converted = result.data.strip()
            
            # ç¢ºä¿è¼¸å‡ºåŒ…å«æ•¸å­—æ¨™èª¿
            if not re.search(r'\d+', converted):
                # å¦‚æœæ²’æœ‰æ•¸å­—æ¨™èª¿ï¼Œä½¿ç”¨ç°¡å–®çš„å¾Œå‚™æ–¹æ¡ˆ
                syllables = self.simple_syllable_split(english_word)
                converted = ' '.join([f"{syl}24" for syl in syllables])
            
            return converted
            
        except Exception as e:
            print(f"English word conversion error for '{english_word}': {e}")
            # ç°¡å–®å¾Œå‚™æ–¹æ¡ˆ
            syllables = self.simple_syllable_split(english_word)
            return ' '.join([f"{syl}24" for syl in syllables])

    def simple_syllable_split(self, word: str) -> list:
        """ç°¡å–®çš„è‹±æ–‡å–®å­—éŸ³ç¯€åˆ†å‰²ï¼ˆå¾Œå‚™æ–¹æ¡ˆï¼‰"""
        word = word.lower()
        
        # å¸¸è¦‹å–®å­—çš„éŸ³ç¯€åˆ†å‰²
        common_splits = {
            'apple': ['a', 'pu', 'er'],
            'google': ['gu', 'ge', 'er'],
            'facebook': ['fei', 'si', 'bu', 'ke'],
            'microsoft': ['mai', 'ke', 'ro', 'so', 'fu', 'te'],
            'iphone': ['ai', 'feng'],
            'hakkast': ['ha', 'ka', 'si', 'te'],
            'chatgpt': ['cha', 'te', 'ji', 'pi', 'ti'],
            'youtube': ['you', 'tu', 'be'],
            'openai': ['o', 'pen', 'ai'],
            'android': ['an', 'zhuo', 'yi', 'de']
        }
        
        if word in common_splits:
            return common_splits[word]
        
        # ç°¡å–®åˆ†å‰²ï¼šæ¯2-3å€‹å­—æ¯ä¸€çµ„
        syllables = []
        i = 0
        while i < len(word):
            if i + 2 < len(word):
                syllables.append(word[i:i+2])
                i += 2
            else:
                syllables.append(word[i:])
                break
        
        return syllables


class AIService:
    def __init__(self):
        if settings.GEMINI_API_KEY:
            genai.configure(api_key=settings.GEMINI_API_KEY)
            self.model = genai.GenerativeModel('gemini-2.5-flash')
        else:
            self.model = None
        
        self.translation_service = TranslationService()
        self.tts_service = TTSService()

# Constants and utility functions from agents.py
CONTEXT_WINDOW_TOKENS = 32000

def count_tokens(text):
    return int(len(text) / 1.5)

def trim_context(context_list, max_tokens=CONTEXT_WINDOW_TOKENS):
    trimmed = []
    total_tokens = 0
    for line in reversed(context_list):
        tokens = count_tokens(line)
        if total_tokens + tokens > max_tokens:
            break
        trimmed.insert(0, line)
        total_tokens += tokens
    return trimmed

def max_chars_for_duration(minutes):
    return int(minutes * 120)

class HostAgent:
    def __init__(self, name, personality, ai_service):
        self.name = name
        self.personality = personality
        self.ai_service = ai_service

    async def reply(self, context_list, all_articles, current_article_idx, turn, is_last_turn):
        trimmed_context = trim_context(context_list[-6:])  # åªä¿ç•™æœ€è¿‘6è¼ª
        context_text = "\n".join(trimmed_context)
        article = all_articles[current_article_idx]
        transition = ""
        if is_last_turn and current_article_idx < len(all_articles) - 1:
            transition = (
                f"\nè«‹åœ¨æœ¬è¼ªç™¼è¨€çµå°¾ï¼Œè‡ªç„¶åœ°å°‡è©±é¡Œå¸¶åˆ°ä¸‹ä¸€å‰‡æ–°èï¼Œä¸è¦ç”¨ã€æ¥ä¸‹ä¾†ã€ç­‰åˆ¶å¼èªï¼Œ"
                f"è€Œæ˜¯ç”¨è©•è«–ã€å»¶ä¼¸ã€æˆ–èˆ‰ä¾‹çš„æ–¹å¼ï¼Œè®“å°è©±é †æš¢éŠœæ¥åˆ°ä¸‹ä¸€ç¯‡ä¸»é¡Œã€‚"
                f"ä¸‹ä¸€ç¯‡ä¸»é¡Œçš„é‡é»æ˜¯ï¼š{all_articles[current_article_idx+1].summary or all_articles[current_article_idx+1].content[:60]}"
            )

        prompt = (
            f"ä½ æ˜¯{self.name}ï¼Œå€‹æ€§æ˜¯{self.personality}ã€‚\n"
            f"è«‹ç”¨{self.personality}çš„èªæ°£ï¼Œæ ¹æ“šç›®å‰å°è©±ç´€éŒ„é€²è¡Œè¨è«–ã€‚\n"
            f"ç›®å‰å°è©±ç´€éŒ„ï¼š\n{context_text}\n"
            f"è«‹ä¸€å®šè¦é¿å…é‡è¤‡å‰é¢å·²ç¶“è¨è«–éçš„å…§å®¹ï¼Œç›¡é‡æå‡ºæ–°çš„è§€é»ã€èˆ‰ä¾‹æˆ–å»¶ä¼¸è¨è«–ï¼Œä¸¦èˆ‡å¦ä¸€ä½ä¸»æŒäººæœ‰äº’å‹•ã€‚\n"
            f"æ¯æ¬¡ç™¼è¨€æœ€å¤š4å¥è©±ï¼Œå…¨ç¨‹è«‹ç”¨åƒæœ‹å‹ä¹‹é–“è¼•é¬†è‡ªç„¶èŠå¤©æ–¹å¼ï¼Œæ™‚ä¸æ™‚åŠ äº›æœ‰è¶£çš„å›è¦†ï¼Œå…§å®¹è¦æœ‰æ·±åº¦èˆ‡äº’å‹•ã€‚"
            f"æ¯å¥è©±ä¹‹é–“è«‹ç”¨å¥è™Ÿåˆ†éš”ï¼Œå›æ‡‰å‰åŠ ä¸Šã€Œ{self.name}: ã€"
            f"{transition}"
        )
        response = await self.ai_service.generate_reply(prompt)
        sentences = response.split("ã€‚")
        limited = "ã€‚".join(sentences[:4]).strip()
        if not limited.startswith(f"{self.name}:"):
            limited = f"{self.name}: {limited}"
        return limited + ("ã€‚" if not limited.endswith("ã€‚") else "")


class AIService:
    def __init__(self):
        if settings.GEMINI_API_KEY:
            genai.configure(api_key=settings.GEMINI_API_KEY)
            self.model = genai.GenerativeModel('gemini-2.5-flash')
        else:
            self.model = None
        
        self.translation_service = TranslationService()
        self.tts_service = TTSService()
    
    async def generate_hakka_podcast_content(self, request: PodcastGenerationRequest) -> Dict[str, Any]:
        """
        Generate Hakka podcast content using the enhanced 4-step pipeline:
        1. Crawl latest content for the topic (if applicable)
        2. Generate Traditional Chinese script using Gemini + crawled content
        3. Translate Chinese to Hakka
        4. Generate Hakka TTS audio
        """
        
        try:
            # Step 1: Crawl latest content for dynamic topics
            crawled_content = await self._crawl_topic_content(request.topic)
            
            # Step 2: Generate Traditional Chinese content using Gemini + crawled content
            chinese_content = await self._generate_chinese_content(request, crawled_content)
            
            # Step 3: Translate Chinese to Hakka
            translation_result = await self.translation_service.translate_chinese_to_hakka(
                chinese_content["content"]
            )
            
            # Step 4: Generate Hakka TTS audio
            tts_result = await self.tts_service.generate_hakka_audio(
                translation_result["hakka_text"],
                translation_result["romanization"]
            )
            
            return {
                "title": chinese_content["title"],
                "chinese_content": chinese_content["content"],
                "hakka_content": translation_result["hakka_text"],
                "romanization": translation_result["romanization"],
                "audio_url": tts_result.get("audio_url"),
                "audio_duration": tts_result.get("duration", 0),
                "sources_used": chinese_content.get("sources_used", []),
                "crawled_articles": len(crawled_content) if crawled_content else 0
            }
            
        except Exception as e:
            print(f"Error in AI pipeline: {e}")
            return await self._generate_fallback_content(request)
    
    async def _crawl_topic_content(self, topic: str) -> List[CrawledContent]:
        """Crawl latest content for dynamic topics like news or research"""
        try:
            # Check if topic requires crawling
            crawling_keywords = [
                "news", "latest", "recent", "current", "update", "research", 
                "gaming", "technology", "science", "politics", "economics"
            ]
            
            topic_lower = topic.lower()
            should_crawl = any(keyword in topic_lower for keyword in crawling_keywords)
            
            if not should_crawl:
                return []
            
            # Determine appropriate crawler topic
            crawler_topic = self._map_to_crawler_topic(topic_lower)
            if not crawler_topic:
                return []
            
            # Use crawl_news function from crawl4ai_service
            result = await crawl_news(crawler_topic, max_articles=5)
            return result
                
        except Exception as e:
            print(f"Error crawling content for topic '{topic}': {e}")
            return []
    
    def _map_to_crawler_topic(self, topic: str) -> str:
        """Map user topic to predefined crawler configurations"""
        mapping = {
            "gaming": "gaming_news",
            "game": "gaming_news", 
            "video game": "gaming_news",
            "esports": "gaming_news",
            "deep learning": "research_deep_learning",
            "machine learning": "research_deep_learning", 
            "ai research": "research_deep_learning",
            "neural network": "research_deep_learning",
            "technology": "technology_news",
            "tech": "technology_news",
            "startup": "technology_news",
            "health": "health_wellness",
            "wellness": "health_wellness",
            "fitness": "health_wellness",
            "climate": "climate_environment",
            "environment": "climate_environment",
            "sustainability": "climate_environment",
            "finance": "finance_economics",
            "economics": "finance_economics",
            "investment": "finance_economics"
        }
        
        for keyword, crawler_topic in mapping.items():
            if keyword in topic:
                return crawler_topic
        
        return ""

    async def _generate_chinese_content(self, request: PodcastGenerationRequest, crawled_content: List[CrawledContent] = None) -> Dict[str, Any]:
        """Generate Traditional Chinese content using Gemini AI"""
        
        if not self.model:
            return self._generate_chinese_fallback(request)
        
        try:
            prompt = self._build_chinese_prompt(request, crawled_content)
            response = self.model.generate_content(prompt)
            
            # Parse the response
            content = response.text
            title = self._extract_title(content)
            
            # Extract sources used
            sources_used = []
            if crawled_content:
                sources_used = list(set(item.source for item in crawled_content))
            
            return {
                "title": title,
                "content": content,
                "sources_used": sources_used
            }
        except Exception as e:
            print(f"Error generating Chinese content with Gemini: {e}")
            return self._generate_chinese_fallback(request)
    
    def _build_chinese_prompt(self, request: PodcastGenerationRequest, crawled_content: List[CrawledContent] = None) -> str:
        """Build the prompt for generating Traditional Chinese content"""
        
        tone_instructions = {
            "casual": "ä½¿ç”¨è¦ªåˆ‡ã€å°è©±çš„èªèª¿ï¼Œå°±åƒå’Œå¥½æœ‹å‹èŠå¤©ä¸€æ¨£ã€‚",
            "educational": "æ¡ç”¨è³‡è¨Šè±å¯Œçš„æ•™å­¸é¢¨æ ¼ï¼Œæ¸…æ¥šè§£é‡‹æ¦‚å¿µã€‚",
            "storytelling": "é‹ç”¨æ•˜äº‹æŠ€å·§å’Œå¼•äººå…¥å‹çš„æ•…äº‹å…ƒç´ ã€‚",
            "interview": "ä»¥è¨ªè«‡æ ¼å¼çµæ§‹åŒ–ï¼ŒåŒ…å«å•é¡Œå’Œè©³ç´°å›ç­”ã€‚"
        }
        
        # Add crawled content to prompt if available
        current_content_section = ""
        if crawled_content:
            current_content_section = "\n\næœ€æ–°ç›¸é—œè³‡è¨Šåƒè€ƒï¼š\n"
            for i, content in enumerate(crawled_content[:3], 1):  # Limit to top 3 articles
                current_content_section += f"\n{i}. æ¨™é¡Œï¼š{content.title}\n"
                current_content_section += f"   ä¾†æºï¼š{content.source}\n"
                current_content_section += f"   æ‘˜è¦ï¼š{content.summary}\n"
            current_content_section += "\nè«‹æ ¹æ“šä»¥ä¸Šæœ€æ–°è³‡è¨Šï¼Œçµåˆå®¢å®¶æ–‡åŒ–è¦–è§’é€²è¡Œæ’­å®¢å…§å®¹å‰µä½œã€‚"
        
        prompt = f"""
è«‹ç‚ºä»¥ä¸‹ä¸»é¡Œå‰µå»ºä¸€å€‹ {request.duration} åˆ†é˜çš„å®¢å®¶æ–‡åŒ–æ’­å®¢è…³æœ¬ï¼š"{request.topic}"

è¦æ±‚ï¼š
- ä½¿ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«
- {tone_instructions.get(request.tone, 'ä½¿ç”¨è¦ªåˆ‡ã€å°è©±çš„èªèª¿')}
- å°ˆæ³¨æ–¼å®¢å®¶æ–‡åŒ–ã€å‚³çµ±å’Œéºç”¢
- å…§å®¹è¦å¼•äººå…¥å‹ä¸”çœŸå¯¦
- åŒ…å«æ–‡åŒ–èƒŒæ™¯å’Œæ­·å²è„ˆçµ¡
- çµæ§‹æ¸…æ™°ï¼šé–‹å ´ç™½ã€ä¸»è¦å…§å®¹ã€çµèª
- èªé€Ÿä¼°ç®—ï¼šæ¯åˆ†é˜ç´„ 50 å­—
{current_content_section}

{"å€‹äººèˆˆè¶£èå…¥ï¼š" + request.interests if request.interests else ""}

è«‹åœ¨ç¬¬ä¸€è¡Œæä¾›å¸å¼•äººçš„æ¨™é¡Œï¼Œç„¶å¾Œæä¾›å®Œæ•´çš„æ’­å®¢è…³æœ¬ã€‚
å…§å®¹æ‡‰è©²é©åˆå¾ŒçºŒç¿»è­¯ç‚ºå®¢å®¶è©±ä¸¦è£½ä½œæˆèªéŸ³æ’­å®¢ã€‚
"""
        
        return prompt
    
    def _extract_title(self, content: str) -> str:
        """Extract title from the generated content"""
        lines = content.strip().split('\n')
        if lines:
            # First non-empty line is likely the title
            for line in lines:
                if line.strip():
                    return line.strip()
        return "Hakka Podcast"
    
    def _generate_chinese_fallback(self, request: PodcastGenerationRequest) -> Dict[str, Any]:
        """Generate fallback Chinese content when Gemini is not available"""
        
        fallback_content = f"""
{request.topic} - å®¢å®¶æ–‡åŒ–æ¢ç´¢

æ­¡è¿ä¾†åˆ°æˆ‘å€‘çš„å®¢å®¶æ’­å®¢ï¼ä»Šå¤©æˆ‘å€‘è¦æ¢è¨é—œæ–¼{request.topic}é€™å€‹è¿·äººçš„ä¸»é¡Œã€‚

[é€™æ˜¯æ¼”ç¤ºç‰ˆæœ¬ã€‚å¦‚éœ€AIç”Ÿæˆå…§å®¹ï¼Œè«‹åœ¨.envæ–‡ä»¶ä¸­é…ç½®æ‚¨çš„Gemini APIå¯†é‘°ã€‚]

å®¢å®¶æ–‡åŒ–æ“æœ‰è±å¯Œçš„å‚³çµ±å’Œæ­·å²ã€‚æˆ‘å€‘çš„ç¥–å…ˆå¾ä¸­åœ‹åŒ—æ–¹é·å¾™è€Œä¾†ï¼Œå¸¶ä¾†äº†ç¨ç‰¹çš„ç¿’ä¿—ã€èªè¨€å’Œé£²é£Ÿå‚³çµ±ï¼Œé€™äº›éƒ½è¢«ä¸–ä»£ä¿å­˜ä¸‹ä¾†ã€‚

ç„¡è«–æˆ‘å€‘ä»¥{request.tone}çš„æ–¹å¼è¨è«–{request.topic}ï¼Œç¸½æœ‰æ–°çš„ç™¼ç¾ç­‰è‘—æˆ‘å€‘å»æ¢ç´¢å®¢å®¶æ–‡åŒ–éºç”¢ã€‚å¾å‚³çµ±æ­Œè¬ å’Œæ•…äº‹åˆ°å¤è€æ™ºæ…§çš„ç¾ä»£è©®é‡‹ï¼Œå®¢å®¶æ–‡åŒ–åœ¨ä¿æŒæ ¸å¿ƒåƒ¹å€¼çš„åŒæ™‚æŒçºŒç™¼å±•ã€‚

å®¢å®¶è©±æœ¬èº«å°±æ˜¯ä¸€å€‹è¡¨é”å¯¶åº«ï¼Œæ•æ‰äº†æˆ‘å€‘æ°‘æ—å …éŸŒä¸æ‹”å’Œç¤¾å€ç²¾ç¥çš„ç²¾é«“ã€‚é€šéé€™äº›æ’­å®¢ï¼Œæˆ‘å€‘å¸Œæœ›èˆ‡æ¯èªä½¿ç”¨è€…å’Œæ­£åœ¨å­¸ç¿’æ–‡åŒ–éºç”¢çš„äººå€‘åˆ†äº«é€™ç¾éº—çš„æ–‡åŒ–ã€‚

æ„Ÿè¬æ‚¨åŠ å…¥æˆ‘å€‘çš„æ–‡åŒ–ä¹‹æ—…ã€‚ä¸‹æ¬¡è¦‹ï¼Œç¹¼çºŒæ¢ç´¢å’Œæ…¶ç¥æ‚¨çš„å®¢å®¶æ ¹æºï¼

[æ™‚é•·ï¼šç´„{request.duration}åˆ†é˜]
"""
        
        return {
            "title": f"{request.topic} - å®¢å®¶æ–‡åŒ–æ¢ç´¢",
            "content": fallback_content
        }
    
    async def _generate_fallback_content(self, request: PodcastGenerationRequest) -> Dict[str, Any]:
        """Generate complete fallback content when services are not available"""
        
        chinese_content = self._generate_chinese_fallback(request)
        
        # Mock translation
        hakka_content = chinese_content["content"].replace("æ­¡è¿", "æ­¡è¿æ±").replace("æˆ‘å€‘", "ä¿š")
        
        return {
            "title": chinese_content["title"],
            "chinese_content": chinese_content["content"],
            "hakka_content": hakka_content,
            "romanization": "",
            "audio_url": None,
            "audio_duration": 0
        }

    async def generate_podcast_script_with_agents(self, articles, max_minutes=25):
        """Generate podcast script using agent-based conversation (merged from agents.py)"""
        ai_service = PydanticAIService()
        host_a = HostAgent("ä½³æ˜€", "ç†æ€§ã€å°ˆæ¥­ã€åˆ†æ", ai_service)
        host_b = HostAgent("æ•æ¬Š", "å¹½é»˜ã€æ´»æ½‘ã€äº’å‹•", ai_service)
        dialogue = []
        total_chars = 0
        max_chars = max_chars_for_duration(max_minutes)
        per_article_chars = max_chars // len(articles)
        turn = 0

        # é–‹å ´
        dialogue.append("ä½³æ˜€: å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯ä½³æ˜€ã€‚")
        dialogue.append("æ•æ¬Š: æˆ‘æ˜¯æ•æ¬Šï¼Œæ­¡è¿æ”¶è½Hakkast å“ˆå®¢æ’­ã€‚")
        dialogue.append("ä½³æ˜€: ä»Šå¤©æˆ‘å€‘ç‚ºå¤§å®¶å¸¶ä¾†ä¸‰å‰‡é‡è¦æ–°èï¼Œè®“æˆ‘å€‘ä¸€èµ·çœ‹çœ‹ï¼")

        for idx, article in enumerate(articles):
            article_chars = 0

            # ç”¨ LLM ç”¢ç”Ÿç²¾ç°¡æ‘˜è¦
            summary_prompt = (
                "è«‹ä½ ç”¨è‡ªç„¶çš„èªæ°£ï¼Œåƒæœ‹å‹èŠå¤©ä¸€æ¨£ï¼Œé †å‹¢å¸¶å‡ºä¸‹é¢é€™å‰‡æ–°èçš„é‡é»æ‘˜è¦ï¼Œ"
                "ä¸è¦ç”¨ã€é€™å‰‡æ–°èçš„é‡é»æ˜¯ã€ã€ã€æ¥ä¸‹ä¾†ã€ç­‰åˆ¶å¼é–‹é ­ï¼Œ"
                "è€Œæ˜¯ç”¨è©•è«–ã€æ„Ÿæƒ³ã€æˆ–å»¶ä¼¸è©±é¡Œçš„æ–¹å¼è‡ªç„¶éŠœæ¥ï¼Œ50å­—ä»¥å…§ï¼š\n"
                f"{article.content or article.summary}"
            )
            brief = await ai_service.generate_reply(summary_prompt)
            # é™åˆ¶æ‘˜è¦æœ€å¤šå››å¥
            sentences = brief.strip().split("ã€‚")
            intro = f"ä½³æ˜€: {'ã€‚'.join(sentences[:5]).strip()}"
            dialogue.append(intro)

            for round in range(30):
                is_last_turn = (article_chars + 100 > per_article_chars * 0.95)
                if article_chars > per_article_chars * 0.95 or total_chars > max_chars * 0.95:
                    break  
                if turn % 2 == 0:
                    reply = await host_a.reply(dialogue, articles, idx, turn, is_last_turn)
                else:
                    reply = await host_b.reply(dialogue, articles, idx, turn, is_last_turn)
                dialogue.append(reply)
                total_chars += len(reply)
                article_chars += len(reply)
                turn += 1

        # ä¸‰ç¯‡æ–°èè¨è«–å®Œï¼Œé€²å…¥æ”¶å°¾
        news_list = "\n".join([f"{i+1}. {(a.summary or a.content)[:60]}" for i, a in enumerate(articles)])

        summary_prompt_a = (
            f"è«‹ä½ ä»¥ä½³æ˜€çš„èº«åˆ†ï¼Œé‡å°ä»Šå¤©è¨è«–çš„ä¸‰å‰‡æ–°èåšä¸€å€‹é‡é»ç¸½çµã€‚\n"
            f"æœ¬é›†ä¸‰å‰‡æ–°èåˆ†åˆ¥æ˜¯ï¼š\n{news_list}\n"
            "è«‹ç›´æ¥ç”¨è‡ªç„¶èªè¨€ç¸½çµä»Šå¤©çš„è¨è«–å…§å®¹ï¼Œå‹™å¿…ä¸å¯å‡ºç¾ä»»ä½•[æ–°èä¸€ä¸»é¡Œ]ã€[çœç•¥]æˆ–ä»»ä½•ä½”ä½ç¬¦ï¼Œ"
            "å…§å®¹è¦å®Œæ•´ã€ç²¾ç°¡ä¸”è²¼åˆæœ¬é›†ä¸»é¡Œï¼Œç´„3~4å¥è©±ï¼Œæ¯å¥è©±ç”¨å¥è™Ÿåˆ†éš”ï¼Œé–‹é ­åŠ ã€Œä½³èŠ¸: ã€"
        )
        summary_a = await ai_service.generate_reply(summary_prompt_a)
        dialogue.append(summary_a.strip())

        summary_prompt_b = (
            "è«‹ä½ ä»¥æ•æ¬Šçš„èº«åˆ†ï¼Œé‡å°ä½³æ˜€çš„ç¸½çµå…§å®¹åšè£œå……æˆ–åˆ†äº«å€‹äººè§€é»ï¼Œ"
            "èªæ°£è¼•é¬†ï¼Œç´„2~3å¥è©±ï¼Œæ¯å¥è©±ç”¨å¥è™Ÿåˆ†éš”ï¼Œé–‹é ­åŠ ã€Œæ•æ¬Š: ã€"
        )
        summary_b = await ai_service.generate_reply(summary_prompt_b)
        dialogue.append(summary_b.strip())

        ending_prompt_a = (
            "è«‹ä½ ä»¥ä½³æ˜€çš„èº«åˆ†ï¼Œç”¨ä¸€æ®µè©±åšæœ¬é›†æ’­å®¢çš„æº«é¦¨çµèªï¼Œ"
            "å…§å®¹è¦å‘¼æ‡‰ä»Šå¤©è¨è«–çš„ä¸‰å‰‡æ–°èï¼Œé–‹é ­åŠ ã€Œä½³æ˜€: ã€ï¼Œä¸è¦æœ‰ä»»ä½•ä½”ä½ç¬¦ã€‚"
        )
        ending_a = await ai_service.generate_reply(ending_prompt_a)
        dialogue.append(ending_a.strip())

        def merge_same_speaker_lines(dialogue_lines):
            merged = []
            buffer = ""
            last_speaker = None
            for line in dialogue_lines:
                line = line.strip()
                if not line:
                    continue
                if line.startswith("ä½³æ˜€:"):
                    speaker = "ä½³æ˜€"
                elif line.startswith("æ•æ¬Š:"):
                    speaker = "æ•æ¬Š"
                else:
                    speaker = None

                if speaker and speaker == last_speaker:
                    buffer += " " + line[len(speaker)+1:].strip()
                else:
                    if buffer:
                        merged.append(buffer)
                    buffer = line
                    last_speaker = speaker
            if buffer:
                merged.append(buffer)
            return merged

        # åˆä½µåŒä¸»æŒäººç™¼è¨€ï¼Œä¸¦åœ¨ä¸åŒä¸»æŒäººæ™‚æ›è¡Œ
        merged_lines = merge_same_speaker_lines(dialogue)
        
        # è™•ç†è‹±æ–‡è½‰æ›
        print("æ­£åœ¨è™•ç†è…³æœ¬ä¸­çš„è‹±æ–‡å…§å®¹...")
        processed_lines = []
        for line in merged_lines:
            # æš«æ™‚è·³éè‹±æ–‡è™•ç†ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹å…§å®¹
            # TODO: å¦‚æœéœ€è¦åœ¨é€™è£¡è™•ç†è‹±æ–‡ï¼Œæ‡‰è©²åœ¨ç¿»è­¯éšæ®µè™•ç†
            processed_lines.append(line)
        
        # è½‰æˆçµæ§‹åŒ–é™£åˆ—
        content = []
        tts_content = []  # æ–°å¢ï¼šå°ˆç‚ºTTSæº–å‚™çš„å…§å®¹
        
        for i, line in enumerate(merged_lines):
            processed_line = processed_lines[i]
            
            if line.startswith("ä½³æ˜€:"):
                content.append(PodcastScriptContent(speaker="ä½³æ˜€", text=line[len("ä½³æ˜€:"):].strip()))
                tts_content.append(PodcastScriptContent(speaker="ä½³æ˜€", text=processed_line[len("ä½³æ˜€:"):].strip()))
            elif line.startswith("æ•æ¬Š:"):
                content.append(PodcastScriptContent(speaker="æ•æ¬Š", text=line[len("æ•æ¬Š:"):].strip()))
                tts_content.append(PodcastScriptContent(speaker="æ•æ¬Š", text=processed_line[len("æ•æ¬Š:"):].strip()))
        
        # å‰µå»ºå…©å€‹ç‰ˆæœ¬çš„è…³æœ¬
        podcast_script = PodcastScript(
            title="Hakkast å“ˆå®¢æ’­æ–°èè¨è«–",
            hosts=["ä½³æ˜€", "æ•æ¬Š"],
            content=content
        )
        
        # TTSç‰ˆæœ¬è…³æœ¬
        tts_podcast_script = PodcastScript(
            title="Hakkast å“ˆå®¢æ’­æ–°èè¨è«–",
            hosts=["ä½³æ˜€", "æ•æ¬Š"],
            content=tts_content
        )
        
        print(f"è…³æœ¬å­—æ•¸ï¼š{sum(len(c.text) for c in content)}")
        
        # è¿”å›åŒ…å«TTSç‰ˆæœ¬çš„çµæœ
        return {
            "original_script": podcast_script,
            "tts_ready_script": tts_podcast_script
        }

    async def process_romanization_for_tts(self, romanization_text: str) -> str:
        """å°ˆé–€è™•ç†romanizationæ¬„ä½ä¸­çš„è‹±æ–‡å–®å­—ï¼Œç‚ºTTSç³»çµ±æº–å‚™çµ±ä¸€æ ¼å¼"""
        try:
            # æª¢æŸ¥æ˜¯å¦åŒ…å«æ²’æœ‰æ•¸å­—æ¨™èª¿çš„è‹±æ–‡å–®å­—
            import re
            
            # å°‹æ‰¾è‹±æ–‡å–®å­—ï¼ˆå­—æ¯çµ„æˆä½†æ²’æœ‰æ•¸å­—æ¨™èª¿ï¼‰
            english_words = re.findall(r'\b[a-zA-Z]+\b', romanization_text)
            
            if not english_words:
                return romanization_text
            
            # è™•ç†æ¯å€‹è‹±æ–‡å–®å­—
            processed_text = romanization_text
            for word in english_words:
                try:
                    converted_word = await self.convert_english_word_to_toned_romanization(word)
                    # æ›¿æ›åŸæ–‡ä¸­çš„è‹±æ–‡å–®å­—
                    processed_text = processed_text.replace(word, converted_word)
                    print(f"è‹±æ–‡è½‰æ›: {word} -> {converted_word}")
                except Exception as e:
                    print(f"è½‰æ›è‹±æ–‡å–®å­— '{word}' å¤±æ•—: {e}")
                    continue
            
            return processed_text
            
        except Exception as e:
            print(f"è™•ç†romanizationå¤±æ•—: {e}")
            return romanization_text

    async def convert_english_word_to_toned_romanization(self, english_word: str) -> str:
        """å°‡å–®å€‹è‹±æ–‡å–®å­—è½‰æ›ç‚ºå¸¶æ¨™èª¿çš„ç¾…é¦¬æ‹¼éŸ³"""
        import re
        
        try:
            if not self.model:
                # å¦‚æœæ²’æœ‰æ¨¡å‹ï¼Œä½¿ç”¨ç°¡å–®åˆ†å‰²
                syllables = self.simple_syllable_split(english_word)
                return " ".join([f"{syl}24" for syl in syllables])
            
            prompt = f"""
è«‹å°‡è‹±æ–‡å–®å­— "{english_word}" è½‰æ›ç‚ºå®¢èªç¾…é¦¬æ‹¼éŸ³ï¼Œæ¯å€‹éŸ³ç¯€éƒ½è¦æœ‰æ•¸å­—æ¨™èª¿ã€‚

åƒè€ƒç¯„ä¾‹ï¼š
- GitHub -> gi24 hab2
- Machine -> ma24 sin24  
- Learning -> lia24 ning24
- Hakkast -> ha24 ka24 si24 te24

è«‹åªå›å‚³è½‰æ›çµæœï¼Œä¸è¦å…¶ä»–èªªæ˜ã€‚
"""
            
            response = await self.model.generate_content_async(prompt)
            result = response.text.strip()
            
            if result and not re.search(r'[a-zA-Z]', result):
                return result
            else:
                # å¦‚æœçµæœåŒ…å«è‹±æ–‡å­—æ¯ï¼Œä½¿ç”¨å¾Œå‚™æ–¹æ¡ˆ
                syllables = self.simple_syllable_split(english_word)
                return " ".join([f"{syl}24" for syl in syllables])
                
        except Exception as e:
            print(f"AIè½‰æ›å¤±æ•—: {e}")
            # ä½¿ç”¨ç°¡å–®åˆ†å‰²ä½œç‚ºå¾Œå‚™
            syllables = self.simple_syllable_split(english_word)
            return " ".join([f"{syl}24" for syl in syllables])

    def simple_syllable_split(self, word: str) -> list:
        """ç°¡å–®çš„éŸ³ç¯€åˆ†å‰²ï¼Œä½œç‚ºå¾Œå‚™æ–¹æ¡ˆ"""
        common_splits = {
            "GitHub": ["gi", "hab"],
            "Machine": ["ma", "sin"],
            "Learning": ["lia", "ning"],
            "Hakkast": ["ha", "ka", "si", "te"],
            "AI": ["ai"],
            "NHS": ["en", "ha", "si"],
            "API": ["a", "pi", "ai"]
        }
        
        if word in common_splits:
            return common_splits[word]
        
        # é»˜èªæ¯2-3å€‹å­—æ¯ç‚ºä¸€å€‹éŸ³ç¯€
        syllables = []
        word_lower = word.lower()
        i = 0
        while i < len(word_lower):
            if i + 2 < len(word_lower):
                syllables.append(word_lower[i:i+2])
                i += 2
            else:
                syllables.append(word_lower[i:])
                break
        
        return syllables if syllables else [word.lower()]


# å¾ agents.py åˆä½µéä¾†çš„ä¸»è¦å‡½æ•¸ï¼Œä¾›å¤–éƒ¨èª¿ç”¨
async def generate_podcast_script_with_agents(articles, max_minutes=25):
    """
    Generate podcast script with agents - main function from agents.py
    This is the primary function for agent-based podcast script generation
    Returns both original and TTS-ready versions
    """
    ai_service_instance = AIService()
    result = await ai_service_instance.generate_podcast_script_with_agents(articles, max_minutes)
    
    # ç‚ºäº†å‘å¾Œå…¼å®¹ï¼Œå¦‚æœèª¿ç”¨è€…æœŸå¾…å–®ä¸€è…³æœ¬ï¼Œè¿”å›åŸå§‹è…³æœ¬
    # ä½†åŒæ™‚æä¾›TTSç‰ˆæœ¬
    if isinstance(result, dict) and "original_script" in result:
        # æ–°æ ¼å¼ï¼šè¿”å›å­—å…¸åŒ…å«å…©å€‹ç‰ˆæœ¬
        return result
    else:
        # èˆŠæ ¼å¼ï¼šè¿”å›å–®ä¸€è…³æœ¬ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
        return result
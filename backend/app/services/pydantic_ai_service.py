"""
Pydantic AI Service for Hakka Podcast Generation
ä½¿ç”¨ Pydantic AI æ¡†æ¶é‡æ§‹çš„ AI æœå‹™ï¼Œæ”¯æ´ TWCC AFS å’Œ Gemini æ¨¡å‹
"""

from typing import Dict, Any, List, Optional
from pydantic import BaseModel
from pydantic_ai import Agent
from pydantic_ai.models.gemini import GeminiModel
from pydantic_ai.models.openai import OpenAIModel
import asyncio
import os
from datetime import datetime

from app.core.config import settings
from app.models.podcast import PodcastGenerationRequest
from app.models.crawler import CrawledContent


# å®šç¾©çµæ§‹åŒ–çš„å›æ‡‰æ¨¡å‹
class PodcastScript(BaseModel):
    """æ’­å®¢è…³æœ¬çµæ§‹åŒ–æ¨¡å‹"""
    title: str
    introduction: str
    main_content: str
    conclusion: str
    estimated_duration_minutes: int
    key_points: List[str]
    sources_mentioned: List[str]


class ContentAnalysis(BaseModel):
    """å…§å®¹åˆ†æçµæœæ¨¡å‹"""
    topic_category: str
    complexity_level: str  # "beginner", "intermediate", "advanced"
    target_audience: str
    recommended_style: str
    content_freshness: str  # "current", "evergreen", "historical"


class PydanticAIService:
    """ä½¿ç”¨ Pydantic AI çš„æ–° AI æœå‹™ï¼Œæ”¯æ´ TWCC AFS å’Œ Gemini æ¨¡å‹"""
    
    def __init__(self, use_twcc: bool = True):
        self.use_twcc = use_twcc
        
        if use_twcc and settings.TWCC_API_KEY and settings.TWCC_BASE_URL:
            # ä½¿ç”¨ TWCC AFS æ¨¡å‹
            print("ğŸ”§ ä½¿ç”¨ TWCC AFS æ¨¡å‹...")
            # è¨­å®šç’°å¢ƒè®Šæ•¸ä¾› OpenAI å®¢æˆ¶ç«¯ä½¿ç”¨
            os.environ["OPENAI_API_KEY"] = settings.TWCC_API_KEY
            os.environ["OPENAI_BASE_URL"] = settings.TWCC_BASE_URL
            self.model = OpenAIModel(settings.TWCC_MODEL_NAME)
        elif settings.GEMINI_API_KEY:
            # ä½¿ç”¨ Gemini æ¨¡å‹ä½œç‚ºå‚™é¸
            print("ğŸ”§ ä½¿ç”¨ Gemini æ¨¡å‹...")
            # è¨­å®šç’°å¢ƒè®Šæ•¸ä¾› Gemini å®¢æˆ¶ç«¯ä½¿ç”¨
            os.environ["GEMINI_API_KEY"] = settings.GEMINI_API_KEY
            self.model = GeminiModel('gemini-1.5-flash')
            self.use_twcc = False
        else:
            raise ValueError("éœ€è¦è¨­å®š TWCC_API_KEY + TWCC_BASE_URL æˆ– GEMINI_API_KEY")
        
        # å‰µå»ºå…§å®¹åˆ†æ Agent
        self.content_analyzer = Agent(
            model=self.model,
            result_type=ContentAnalysis,
            system_prompt="""
            ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å…§å®¹åˆ†æå¸«ï¼Œå°ˆé–€åˆ†ææ’­å®¢ä¸»é¡Œå’Œå—çœ¾éœ€æ±‚ã€‚
            åˆ†æç”¨æˆ¶æä¾›çš„ä¸»é¡Œï¼Œåˆ¤æ–·ï¼š
            1. ä¸»é¡Œé¡åˆ¥ï¼ˆç§‘æŠ€ã€å¨›æ¨‚ã€æ•™è‚²ã€æ–°èç­‰ï¼‰
            2. è¤‡é›œåº¦ç­‰ç´šï¼ˆåˆå­¸è€…ã€ä¸­ç´šã€é«˜ç´šï¼‰
            3. ç›®æ¨™å—çœ¾
            4. æ¨è–¦çš„æ’­å®¢é¢¨æ ¼
            5. å…§å®¹æ™‚æ•ˆæ€§
            
            è«‹ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰ï¼Œä¸¦æä¾›å°ˆæ¥­çš„åˆ†æçµæœã€‚
            """
        )
        
        # å‰µå»ºè…³æœ¬ç”Ÿæˆ Agent
        self.script_generator = Agent(
            model=self.model,
            result_type=PodcastScript,
            system_prompt="""
            ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å®¢èªæ’­å®¢è…³æœ¬å‰µä½œè€…ã€‚
            
            ä»»å‹™ï¼šæ ¹æ“šæä¾›çš„ä¸»é¡Œå’Œå…§å®¹åˆ†æï¼Œå‰µä½œä¸€ä»½çµæ§‹å®Œæ•´çš„æ’­å®¢è…³æœ¬ã€‚
            
            è…³æœ¬è¦æ±‚ï¼š
            1. æ¨™é¡Œè¦å¸å¼•äººä¸”ç¬¦åˆå®¢èªæ–‡åŒ–
            2. é–‹å ´è¦è¦ªåˆ‡è‡ªç„¶ï¼Œç¬¦åˆå®¢èªæ’­å®¢é¢¨æ ¼
            3. ä¸»è¦å…§å®¹è¦è±å¯Œæœ‰è¶£ï¼Œé©åˆå£èªè¡¨é”
            4. çµå°¾è¦æº«é¦¨ï¼Œé¼“å‹µè½çœ¾åƒèˆ‡
            5. ä¼°ç®—åˆç†çš„æ’­æ”¾æ™‚é•·
            6. æå–é—œéµè¦é»
            7. åˆ—å‡ºå¯èƒ½çš„è³‡æ–™ä¾†æº
            
            èªè¨€ï¼šè«‹ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«ï¼Œå¾ŒçºŒæœƒç¿»è­¯æˆå®¢èªã€‚
            é¢¨æ ¼ï¼šè¦ªåˆ‡ã€æº«æš–ã€å…·æœ‰å®¢å®¶æ–‡åŒ–ç‰¹è‰²ã€‚
            é•·åº¦ï¼šæ ¹æ“šç”¨æˆ¶éœ€æ±‚èª¿æ•´ï¼Œé è¨­10-15åˆ†é˜çš„æ’­å®¢å…§å®¹ã€‚
            """
        )

    async def analyze_content_requirements(self, topic: str, tone: str = "casual") -> ContentAnalysis:
        """åˆ†æå…§å®¹éœ€æ±‚å’Œå—çœ¾"""
        try:
            result = await self.content_analyzer.run(
                f"è«‹åˆ†æé€™å€‹æ’­å®¢ä¸»é¡Œï¼š'{topic}'ï¼Œæ’­å®¢é¢¨æ ¼åå‘ï¼š{tone}"
            )
            return result.data
        except Exception as e:
            print(f"Content analysis error: {e}")
            # è¿”å›é è¨­åˆ†æçµæœ
            return ContentAnalysis(
                topic_category="é€šç”¨",
                complexity_level="intermediate",
                target_audience="ä¸€èˆ¬è½çœ¾",
                recommended_style="å°è©±å¼",
                content_freshness="evergreen"
            )

    async def generate_podcast_script(
        self, 
        request: PodcastGenerationRequest,
        crawled_content: Optional[List[CrawledContent]] = None,
        content_analysis: Optional[ContentAnalysis] = None
    ) -> PodcastScript:
        """ç”Ÿæˆçµæ§‹åŒ–çš„æ’­å®¢è…³æœ¬"""
        
        # å¦‚æœæ²’æœ‰å…§å®¹åˆ†æï¼Œå…ˆé€²è¡Œåˆ†æ
        if not content_analysis:
            content_analysis = await self.analyze_content_requirements(
                request.topic, 
                request.tone or "casual"
            )
        
        # æº–å‚™ä¸Šä¸‹æ–‡è³‡è¨Š
        context_info = f"""
        ä¸»é¡Œï¼š{request.topic}
        é¢¨æ ¼ï¼š{request.tone or 'casual'}
        ç›®æ¨™æ™‚é•·ï¼š{request.duration or 10} åˆ†é˜
        
        å…§å®¹åˆ†æçµæœï¼š
        - é¡åˆ¥ï¼š{content_analysis.topic_category}
        - è¤‡é›œåº¦ï¼š{content_analysis.complexity_level}
        - ç›®æ¨™å—çœ¾ï¼š{content_analysis.target_audience}
        - æ¨è–¦é¢¨æ ¼ï¼š{content_analysis.recommended_style}
        - å…§å®¹æ™‚æ•ˆæ€§ï¼š{content_analysis.content_freshness}
        """
        
        # å¦‚æœæœ‰çˆ¬å–çš„å…§å®¹ï¼ŒåŠ å…¥åƒè€ƒè³‡æ–™
        if crawled_content:
            context_info += "\n\nåƒè€ƒè³‡æ–™ï¼š\n"
            for content in crawled_content[:3]:  # é™åˆ¶ä½¿ç”¨å‰3ç¯‡æ–‡ç« 
                context_info += f"- æ¨™é¡Œï¼š{content.title}\n  æ‘˜è¦ï¼š{content.summary[:200]}...\n"
        
        try:
            result = await self.script_generator.run(context_info)
            return result.data
        except Exception as e:
            print(f"Script generation error: {e}")
            # è¿”å›å‚™ç”¨è…³æœ¬
            return self._create_fallback_script(request)

    async def generate_complete_podcast_content(
        self, 
        request: PodcastGenerationRequest,
        crawled_content: Optional[List[CrawledContent]] = None
    ) -> Dict[str, Any]:
        """å®Œæ•´çš„æ’­å®¢å…§å®¹ç”Ÿæˆæµç¨‹"""
        
        try:
            # Step 1: åˆ†æå…§å®¹éœ€æ±‚
            print("ğŸ” æ­£åœ¨åˆ†æå…§å®¹éœ€æ±‚...")
            content_analysis = await self.analyze_content_requirements(request.topic, request.tone)
            
            # Step 2: ç”Ÿæˆçµæ§‹åŒ–è…³æœ¬
            print("ğŸ“ æ­£åœ¨ç”Ÿæˆæ’­å®¢è…³æœ¬...")
            script = await self.generate_podcast_script(request, crawled_content, content_analysis)
            
            # Step 3: çµ„åˆå®Œæ•´å…§å®¹
            full_content = f"""
æ¨™é¡Œï¼š{script.title}

é–‹å ´ï¼š
{script.introduction}

ä¸»è¦å…§å®¹ï¼š
{script.main_content}

çµèªï¼š
{script.conclusion}
"""
            
            return {
                "success": True,
                "model_info": {
                    "provider": "TWCC AFS" if self.use_twcc else "Google Gemini",
                    "model_name": settings.TWCC_MODEL_NAME if self.use_twcc else "gemini-1.5-flash"
                },
                "content_analysis": content_analysis.dict(),
                "structured_script": script.dict(),
                "full_content": full_content,
                "generation_timestamp": datetime.now().isoformat(),
                "processing_steps": [
                    "å…§å®¹éœ€æ±‚åˆ†æ",
                    "çµæ§‹åŒ–è…³æœ¬ç”Ÿæˆ", 
                    "å…§å®¹æ•´åˆå®Œæˆ"
                ]
            }
            
        except Exception as e:
            print(f"Complete generation error: {e}")
            return {
                "success": False,
                "error": str(e),
                "fallback_content": self._create_fallback_script(request).dict()
            }

    def _create_fallback_script(self, request: PodcastGenerationRequest) -> PodcastScript:
        """å‰µå»ºå‚™ç”¨è…³æœ¬"""
        return PodcastScript(
            title=f"é—œæ–¼{request.topic}çš„å®¢èªæ’­å®¢",
            introduction=f"å¤§å®¶å¥½ï¼Œæ­¡è¿æ”¶è½ä»Šå¤©çš„å®¢èªæ’­å®¢ã€‚ä»Šå¤©æˆ‘å€‘è¦èŠçš„ä¸»é¡Œæ˜¯{request.topic}ã€‚",
            main_content=f"è®“æˆ‘å€‘ä¸€èµ·ä¾†æ¢è¨{request.topic}é€™å€‹æœ‰è¶£çš„è©±é¡Œã€‚é€™æ˜¯ä¸€å€‹å€¼å¾—æ·±å…¥äº†è§£çš„ä¸»é¡Œï¼Œè®“æˆ‘å€‘å¾ä¸åŒè§’åº¦ä¾†çœ‹çœ‹é€™å€‹è­°é¡Œã€‚",
            conclusion="è¬è¬å¤§å®¶çš„æ”¶è½ï¼Œå¸Œæœ›ä»Šå¤©çš„å…§å®¹å°æ‚¨æœ‰æ‰€å¹«åŠ©ã€‚æˆ‘å€‘ä¸‹æ¬¡å†è¦‹ï¼",
            estimated_duration_minutes=request.duration or 10,
            key_points=[f"{request.topic}ç›¸é—œè¦é»"],
            sources_mentioned=["ä¸€èˆ¬çŸ¥è­˜"]
        )


# ä½¿ç”¨ç¯„ä¾‹å’Œæ¸¬è©¦å‡½æ•¸
async def test_pydantic_ai_service():
    """æ¸¬è©¦ Pydantic AI æœå‹™"""
    try:
        print("ğŸ§ª é–‹å§‹æ¸¬è©¦ Pydantic AI æœå‹™...")
        
        # æ¸¬è©¦ TWCC æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            service = PydanticAIService(use_twcc=True)
            print("âœ… æˆåŠŸåˆå§‹åŒ– TWCC AFS æœå‹™")
        except Exception as e:
            print(f"âš ï¸ TWCC åˆå§‹åŒ–å¤±æ•—: {e}")
            print("ğŸ”„ å˜—è©¦ä½¿ç”¨ Gemini å‚™ç”¨æ¨¡å‹...")
            service = PydanticAIService(use_twcc=False)
            print("âœ… æˆåŠŸåˆå§‹åŒ– Gemini æœå‹™")
        
        # æ¸¬è©¦è«‹æ±‚
        test_request = PodcastGenerationRequest(
            topic="å®¢å®¶å‚³çµ±æ–‡åŒ–èˆ‡ç¾ä»£ç§‘æŠ€çš„çµåˆ",
            tone="educational",
            duration=15
        )
        
        print(f"ğŸ“‹ æ¸¬è©¦ä¸»é¡Œ: {test_request.topic}")
        print(f"ğŸ“‹ æ¸¬è©¦é¢¨æ ¼: {test_request.tone}")
        print(f"ğŸ“‹ ç›®æ¨™æ™‚é•·: {test_request.duration} åˆ†é˜")
        
        # åŸ·è¡Œå®Œæ•´ç”Ÿæˆæµç¨‹
        result = await service.generate_complete_podcast_content(test_request)
        print("ğŸ‰ ç”Ÿæˆçµæœï¼š", result)
        return result
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None


async def test_twcc_models():
    """æ¸¬è©¦ä¸åŒçš„ TWCC æ¨¡å‹"""
    twcc_models = [
        "llama3.3-ffm-70b-32k-chat",  # æœ€æ–°çš„ FFM æ¨¡å‹
        "llama3.1-ffm-70b-32k-chat",  # Llama3.1 FFM
        "llama3-ffm-70b-chat",        # Llama3 FFM
        "taide-lx-7b-chat"            # å°ç£æœ¬åœŸåŒ–æ¨¡å‹
    ]
    
    for model_name in twcc_models:
        print(f"\nğŸ§ª æ¸¬è©¦æ¨¡å‹: {model_name}")
        try:
            # æš«æ™‚ä¿®æ”¹é…ç½®
            original_model = getattr(settings, 'TWCC_MODEL_NAME', '')
            settings.TWCC_MODEL_NAME = model_name
            
            service = PydanticAIService(use_twcc=True)
            
            test_request = PodcastGenerationRequest(
                topic="å®¢å®¶æ–‡åŒ–èˆ‡AIç§‘æŠ€",
                tone="casual",
                duration=10
            )
            
            result = await service.generate_complete_podcast_content(test_request)
            print(f"âœ… {model_name} æ¸¬è©¦æˆåŠŸ")
            
            # æ¢å¾©åŸè¨­å®š
            settings.TWCC_MODEL_NAME = original_model
            
        except Exception as e:
            print(f"âŒ {model_name} æ¸¬è©¦å¤±æ•—: {e}")
            continue


if __name__ == "__main__":
    # åŸ·è¡Œæ¸¬è©¦
    asyncio.run(test_pydantic_ai_service())
